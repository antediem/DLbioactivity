{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from build_vocab import WordVocab\n",
    "from dataset import Seq2seqDataset\n",
    "\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "EOS = 2\n",
    "SOS = 3\n",
    "MASK = 4\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function. No batch support?\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model) # (T,H)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TrfmSeq2seq(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_layers, dropout=0.1):\n",
    "        super(TrfmSeq2seq, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(in_size, hidden_size)\n",
    "        self.pe = PositionalEncoding(hidden_size, dropout)\n",
    "        self.trfm = nn.Transformer(d_model=hidden_size, nhead=4, \n",
    "        num_encoder_layers=n_layers, num_decoder_layers=n_layers, dim_feedforward=hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: (T,B)\n",
    "        embedded = self.embed(src)  # (T,B,H)\n",
    "        embedded = self.pe(embedded) # (T,B,H)\n",
    "        hidden = self.trfm(embedded, embedded) # (T,B,H)\n",
    "        out = self.out(hidden) # (T,B,V)\n",
    "        out = F.log_softmax(out, dim=2) # (T,B,V)\n",
    "        return out # (T,B,V)\n",
    "\n",
    "    def _encode(self, src):\n",
    "        # src: (T,B)\n",
    "        embedded = self.embed(src)  # (T,B,H)\n",
    "        embedded = self.pe(embedded) # (T,B,H)\n",
    "        output = embedded\n",
    "        for i in range(self.trfm.encoder.num_layers - 1):\n",
    "            output = self.trfm.encoder.layers[i](output, None)  # (T,B,H)\n",
    "        penul = output.detach().numpy()\n",
    "        output = self.trfm.encoder.layers[-1](output, None)  # (T,B,H)\n",
    "        if self.trfm.encoder.norm:\n",
    "            output = self.trfm.encoder.norm(output) # (T,B,H)\n",
    "        output = output.detach().numpy()\n",
    "        # mean, max, first*2\n",
    "        return np.hstack([np.mean(output, axis=0), np.max(output, axis=0), output[0,:,:], penul[0,:,:] ]) # (B,4H)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        # src: (T,B)\n",
    "        batch_size = src.shape[1]\n",
    "        if batch_size<=100:\n",
    "            return self._encode(src)\n",
    "        else: # Batch is too large to load\n",
    "            print('There are {:d} molecules. It will take a little time.'.format(batch_size))\n",
    "            st,ed = 0,100\n",
    "            out = self._encode(src[:,st:ed]) # (B,4H)\n",
    "            while ed<batch_size:\n",
    "                st += 100\n",
    "                ed += 100\n",
    "                out = np.concatenate([out, self._encode(src[:,st:ed])], axis=0)\n",
    "            return out\n",
    "\n",
    "#     return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, vocab):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for b, sm in enumerate(test_loader):\n",
    "        sm = torch.t(sm.cuda()) # (T,B)\n",
    "        with torch.no_grad():\n",
    "            output = model(sm) # (T,B,V)\n",
    "        \n",
    "        acc = 0.#torch.eq(torch.sum(torch.eq(torch.max(output, dim=2).values, sm), dim=0), sm.shape[0]).sum()\n",
    "        \n",
    "        loss = F.nll_loss(output.view(-1, len(vocab)),\n",
    "                               sm.contiguous().view(-1),\n",
    "                               ignore_index=PAD)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "    return total_loss / len(test_loader), total_acc / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Args = namedtuple('Args', ['n_epoch', 'vocab', 'data', 'outdir', 'name', 'seq_len', 'batch_size', 'n_worker', 'hidden',\\\n",
    "                         'n_layer', 'n_head', 'lr', 'hpu'])\n",
    "\n",
    "args = Args(5, 'vocab.pkl', 'my_train_smiles.csv','result','ST',220,8,4,256,4,4,1e-4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Train size: 1672298\n",
      "Test size: 50000\n",
      "TrfmSeq2seq(\n",
      "  (embed): Embedding(45, 256)\n",
      "  (pe): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (trfm): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=256, out_features=45, bias=True)\n",
      ")\n",
      "Total parameters: 4245037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter     0 | loss 1.893 | ppl 6.636\n",
      "Val   1: iter     0 | loss 1.877 | ppl 6.532\n",
      "acc:  0.0\n",
      "[!] saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [12:10,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    10 | loss 1.843 | ppl 6.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [12:13,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    20 | loss 1.120 | ppl 3.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [12:19,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    30 | loss 0.080 | ppl 1.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [12:24,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    40 | loss 0.044 | ppl 1.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [12:26,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    50 | loss 0.035 | ppl 1.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [12:28,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    60 | loss 0.015 | ppl 1.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [12:30,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   1: iter    70 | loss 0.003 | ppl 1.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [12:31, 10.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0c9ed8d55d8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         loss = F.nll_loss(output.view(-1, len(vocab)),\n\u001b[0;32m     30\u001b[0m                 sm.contiguous().view(-1), ignore_index=PAD)\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "print('Loading dataset...')\n",
    "vocab = WordVocab.load_vocab(args.vocab)\n",
    "dataset = Seq2seqDataset(pd.read_csv(args.data)['first'].values, vocab)\n",
    "test_size = 50000\n",
    "train, test = torch.utils.data.random_split(dataset, [len(dataset)-test_size, test_size])\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True, num_workers=args.n_worker)\n",
    "test_loader = DataLoader(test, batch_size=args.batch_size, shuffle=False, num_workers=args.n_worker)\n",
    "print('Train size:', len(train))\n",
    "print('Test size:', len(test))\n",
    "del dataset, train, test\n",
    "\n",
    "model = TrfmSeq2seq(len(vocab), args.hidden, len(vocab), args.n_layer).cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.normpath('trfm_new_1_120000.pkl')))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "print(model)\n",
    "print('Total parameters:', sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "best_loss = None\n",
    "for e in range(1, 2):#args.n_epoch):\n",
    "    for b, sm in tqdm(enumerate(train_loader)):\n",
    "        sm = torch.t(sm.cuda()) # (T,B)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sm) # (T,B,V)\n",
    "        loss = F.nll_loss(output.view(-1, len(vocab)),\n",
    "                sm.contiguous().view(-1), ignore_index=PAD)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if b%10==0:\n",
    "            print('Train {:3d}: iter {:5d} | loss {:.3f} | ppl {:.3f}'.format(e, b, loss.item(), math.exp(loss.item())))\n",
    "        if b%100==0:\n",
    "            loss,acc = evaluate(model, test_loader, vocab)\n",
    "            print('Val {:3d}: iter {:5d} | loss {:.3f} | ppl {:.3f}'.format(e, b, loss, math.exp(loss)))\n",
    "            print('acc: ', acc)\n",
    "            # Save the model if the validation loss is the best we've seen so far.\n",
    "            if not best_loss or loss < best_loss:\n",
    "                print(\"[!] saving model...\")\n",
    "                if not os.path.isdir(\".save\"):\n",
    "                    os.makedirs(\".save\")\n",
    "                torch.save(model.state_dict(), './.save/trfm_new_%d_%d.pkl' % (e,b))\n",
    "                best_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 1., 1.]]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "output = torch.zeros(2,3,5) + torch.ge(torch.randn(2,3,5), torch.as_tensor(0.5))\n",
    "print(output)\n",
    "sm = torch.ones(2,3)\n",
    "print(sm)\n",
    "torch.eq(torch.sum(torch.eq(torch.max(output, dim=2).values, sm), dim=0), sm.shape[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
