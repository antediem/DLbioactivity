{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "run_Pham2019_v2_ourDS_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJqGyfKkoHQD"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMF9bTpR71sB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9ea259-52e1-4bba-e75c-741a6d399775"
      },
      "source": [
        "#https://drive.google.com/file/d/1r_hC1sa1H2Ht3ZGlp-rkWbcN1a-CIr8I/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1BOzwXO0sYPmsoMMPGpDiJxuZbafKGe9N/view?usp=sharing\n",
        "!gdown --id \"1BOzwXO0sYPmsoMMPGpDiJxuZbafKGe9N\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BOzwXO0sYPmsoMMPGpDiJxuZbafKGe9N\n",
            "To: /content/hiv1_hcv.csv\n",
            "5.45GB [01:45, 51.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M-qQZwRh0UP"
      },
      "source": [
        "path2data = 'hiv1_hcv.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wlrHWoZtKU0"
      },
      "source": [
        "'''\n",
        "use subset of the original hiv1_hcv if you don't have 20Gb RAM!\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "subset = pd.read_csv(path2data).sample(frac=0.1)\n",
        "\n",
        "subset['active'] = subset['active'].replace('hcv',0)\n",
        "subset['active'] = subset['active'].replace('hiv1',1)\n",
        "# df['active'] = df['active'].replace('flua',2)\n",
        "\n",
        "subset.to_csv('subset_hiv1_hcv.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "del subset\n",
        "path2data = 'subset_hiv1_hcv.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h4YXtrFsU5g"
      },
      "source": [
        "device = 'cuda'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aoppwr3wcT6"
      },
      "source": [
        "#dataset.py\n",
        "\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import numpy as np\n",
        "import os, glob\n",
        "import json\n",
        "\n",
        "\n",
        "def read_data(data_path):\n",
        "    data = None\n",
        "    if data_path.endswith('.csv'):\n",
        "        try:\n",
        "            #data = pd.read_json(data_path, lines=True, nrows=100, chunksize=1000)\n",
        "            data = pd.read_csv(data_path)\n",
        "        except ValueError:\n",
        "            print('ValueError')\n",
        "            #data = pd.read_json(data_path)\n",
        "    #if data_path.endswith('.zip'):\n",
        "        #try:\n",
        "            #data = pd.read_json(data_path, compression='zip', lines=True)\n",
        "        #except ValueError:\n",
        "            #data = pd.read_json(data_path, compression='zip')\n",
        "    return data\n",
        "\n",
        "\n",
        "def train_validation_split(data_path):\n",
        "    if os.path.isdir(data_path):\n",
        "        train_path = os.path.join(data_path, 'train.csv')\n",
        "        val_path = os.path.join(data_path, 'val.csv')\n",
        "    else:\n",
        "        train_path = data_path.split('.')[0] + '_' + 'train.csv'\n",
        "        val_path = data_path.split('.')[0] + '_' + 'val.csv'\n",
        "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
        "        # return read_data(train_path), read_data(val_path)\n",
        "        return pd.read_csv(train_path), pd.read_csv(val_path)\n",
        "    data = read_data(data_path)\n",
        "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "    print('Train')\n",
        "    print(train_data.shape)\n",
        "    train_data.to_csv(train_path, index=False)\n",
        "    print('Val')\n",
        "    print(val_data.shape)\n",
        "    val_data.to_csv(val_path, index=False)\n",
        "    return train_data, val_data\n",
        "\n",
        "\n",
        "def train_cross_validation_split(data_path):\n",
        "    dir_path = os.path.dirname(os.path.abspath(data_path))\n",
        "    fold_dirs = glob.glob(os.path.join(dir_path, 'folds_*'))\n",
        "    if len(fold_dirs) == 5:\n",
        "        for fold_dir in fold_dirs:\n",
        "            train_path = os.path.join(fold_dir, 'train.csv')\n",
        "            val_path = os.path.join(fold_dir, 'val.csv')\n",
        "            yield pd.read_csv(train_path), pd.read_csv(val_path)\n",
        "    else:\n",
        "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        data = read_data(data_path)\n",
        "        for i, (train_ids, val_ids) in enumerate(kfold.split(X=data.drop('active', axis=1).values,\n",
        "                                                             y=data['active'].values)):\n",
        "            train_data = data.iloc[train_ids, :]\n",
        "            val_data = data.iloc[val_ids, :]\n",
        "            # os.makedirs(os.path.join(dir_path, 'folds_{}'.format(i)), exist_ok=True)\n",
        "            # train_data.to_json(os.path.join(os.path.join(dir_path, 'folds_{}'.format(i)), 'train.json'))\n",
        "            # val_data.to_json(os.path.join(os.path.join(dir_path, 'folds_{}'.format(i)), 'val.json'))\n",
        "\n",
        "            yield train_data, val_data\n",
        "\n",
        "\n",
        "class ANYDataset(data.Dataset):\n",
        "    def __init__(self, data, infer=False):\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            self.data = data\n",
        "        elif isinstance(data, str):\n",
        "            self.data = read_data(data)\n",
        "        #self.NON_MORD_NAMES = ['smile_ft', 'id', 'subset', 'quinazoline', 'pyrimidine', 'smiles', 'active']\n",
        "        self.NON_MORD_NAMES = ['smile_ft', 'smiles', 'active']\n",
        "        self.infer = infer\n",
        "\n",
        "        # Standardize mord features\n",
        "        scl = StandardScaler()\n",
        "        self.mord_ft = scl.fit_transform(self.data.drop(columns=self.NON_MORD_NAMES).astype(np.float64)).tolist()\n",
        "        self.non_mord_ft_temp = self.data['smile_ft'].values.tolist()\n",
        "        self.non_mord_ft = []\n",
        "        for i in range(len(self.non_mord_ft_temp)):\n",
        "          self.non_mord_ft.append(json.loads(self.non_mord_ft_temp[i]))\n",
        "        self.smiles = self.data['smiles'].values.tolist()\n",
        "        self.label = self.data['active'].values.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.infer:\n",
        "            return self.smiles[idx], self.mord_ft[idx], self.non_mord_ft[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.mord_ft[idx], self.non_mord_ft[idx], self.label[idx]\n",
        "\n",
        "    def get_dim(self, ft):\n",
        "        if ft == 'non_mord':\n",
        "            return len(self.non_mord_ft[0])\n",
        "        if ft == 'mord':\n",
        "            return len(self.mord_ft[0])\n",
        "\n",
        "    def get_smile_ft(self):\n",
        "        return self.non_mord_ft"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIaUMzztMyD6",
        "outputId": "e2f55128-67a6-445a-b4f4-361f0f15646c"
      },
      "source": [
        "train_data, val_data = train_validation_split(path2data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "(8715, 865)\n",
            "Val\n",
            "(2179, 865)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lepa81EVo6UQ"
      },
      "source": [
        "train_dataset = ANYDataset(train_data, True)\n",
        "val_dataset = ANYDataset(val_data, True)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOTot7BPuvFg",
        "outputId": "365d9bca-2585-4503-9d42-487b71a63a6e"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('O=C(Nc1ccccc1)C2CCN(CC2)S(=O)(=O)c3ccc4OCCOc4c3',\n",
              " [-0.12477677497720815,\n",
              "  0.16997366858129753,\n",
              "  0.19944471464629376,\n",
              "  0.044969534265017326,\n",
              "  -0.2515138661932105,\n",
              "  -0.15929467829346314,\n",
              "  -0.095745712764554,\n",
              "  0.13034938319307443,\n",
              "  0.2522470364622163,\n",
              "  -0.17062190595282817,\n",
              "  0.7820400988084859,\n",
              "  0.0636185085151905,\n",
              "  0.48885857108214104,\n",
              "  -0.690802506655947,\n",
              "  -0.5867501053463648,\n",
              "  0.7249459014764524,\n",
              "  0.15532818814395566,\n",
              "  0.12445747414584754,\n",
              "  0.35492081797602826,\n",
              "  0.0750212618337784,\n",
              "  0.11553023164584444,\n",
              "  0.44527709845617447,\n",
              "  -0.17376866165045968,\n",
              "  -0.09824097196419096,\n",
              "  -0.1087649975641443,\n",
              "  0.06397351858782278,\n",
              "  -0.1403196626314968,\n",
              "  0.420233608446911,\n",
              "  0.5618025822911455,\n",
              "  -0.1911834242348009,\n",
              "  -0.14192439068512502,\n",
              "  -0.011475957513711645,\n",
              "  -0.23641333721835917,\n",
              "  -0.4174944181534245,\n",
              "  0.21971575560739257,\n",
              "  -0.19006305795893863,\n",
              "  -0.4137313913315446,\n",
              "  -0.05387300997095499,\n",
              "  0.24129816162349682,\n",
              "  -0.5637374811561482,\n",
              "  -0.24395225103135704,\n",
              "  0.33871155776564144,\n",
              "  -0.32633538895619635,\n",
              "  -0.6010131041706702,\n",
              "  0.26966888068613903,\n",
              "  -0.3117214246065341,\n",
              "  -0.5417561639936372,\n",
              "  0.28720174967073314,\n",
              "  0.5555883520923351,\n",
              "  -0.5242167118437467,\n",
              "  -0.21621516846809033,\n",
              "  0.26693661033137295,\n",
              "  -0.3039559629793478,\n",
              "  -0.29164464069554075,\n",
              "  0.20386950301232018,\n",
              "  -0.2502528508223048,\n",
              "  -0.4186473684493425,\n",
              "  0.2021553542576576,\n",
              "  0.39275674371784147,\n",
              "  -0.419584079924298,\n",
              "  -0.1232105707075086,\n",
              "  0.3005975152369784,\n",
              "  -0.00850766930905131,\n",
              "  0.34688565548384964,\n",
              "  -0.3637813077464913,\n",
              "  -0.15366340920547739,\n",
              "  0.11861314501033512,\n",
              "  0.2813646872142759,\n",
              "  0.3951869111355431,\n",
              "  0.1359613490118553,\n",
              "  1.946573095942126,\n",
              "  -0.23292574306158453,\n",
              "  -0.8873813418462727,\n",
              "  -1.5970001208550926,\n",
              "  -0.5850167957435832,\n",
              "  1.8955157544442527,\n",
              "  -1.0499988452916043,\n",
              "  0.14427890417519457,\n",
              "  0.6645924930119175,\n",
              "  0.02489995808283665,\n",
              "  -0.19884056275258138,\n",
              "  -0.07392136560991736,\n",
              "  -0.838062623322487,\n",
              "  -0.0641016631134005,\n",
              "  -0.19138917996581242,\n",
              "  -0.24439646821470606,\n",
              "  -0.04083458619359614,\n",
              "  -0.1298096443127033,\n",
              "  -0.04374384705795376,\n",
              "  -0.7609906449969074,\n",
              "  -0.3990552873134616,\n",
              "  -0.044388379028206866,\n",
              "  -0.6317226066293887,\n",
              "  0.30834563912964824,\n",
              "  -0.0614952940843509,\n",
              "  -0.3098013916638161,\n",
              "  -0.1609126671982067,\n",
              "  0.00852135144095637,\n",
              "  -0.43204330300910637,\n",
              "  0.3720811908966238,\n",
              "  -1.1169938846225842,\n",
              "  -1.6652996867706775,\n",
              "  0.2592836736595807,\n",
              "  -1.573352985519608,\n",
              "  -0.019977422636754172,\n",
              "  -1.0122665965779036,\n",
              "  -0.4398253540338837,\n",
              "  -1.6751035541790031,\n",
              "  -1.690661241162684,\n",
              "  -0.4203329431559045,\n",
              "  -0.10045733823786883,\n",
              "  -0.05946898636185866,\n",
              "  0.8384680484348807,\n",
              "  -0.5257381444793285,\n",
              "  1.3312694877093922,\n",
              "  -0.11840054007324295,\n",
              "  0.795456130506067,\n",
              "  -0.18991837504817077,\n",
              "  0.22971127228416888,\n",
              "  0.058788498428825525,\n",
              "  -0.09262568997277028,\n",
              "  -0.35194755905049274,\n",
              "  -0.07080710198754804,\n",
              "  -0.15881831263460455,\n",
              "  -0.12279913926471774,\n",
              "  -0.08439157354377744,\n",
              "  -0.0601128489474738,\n",
              "  -0.16785479418403254,\n",
              "  -0.19189681863530372,\n",
              "  -0.15534921363112839,\n",
              "  -0.12865923463567538,\n",
              "  -0.12474343533138067,\n",
              "  -0.17330216426792402,\n",
              "  0.2682523871376965,\n",
              "  -0.1114516179150941,\n",
              "  -0.0001378072471590001,\n",
              "  -0.475626528627702,\n",
              "  -0.1491158020791072,\n",
              "  0.28686734740777003,\n",
              "  -0.07344611651034316,\n",
              "  -0.10732089624857231,\n",
              "  -0.0978900728252322,\n",
              "  -0.08923725468939568,\n",
              "  0.13607184184930834,\n",
              "  0.02461077098388688,\n",
              "  -0.05006019278351643,\n",
              "  0.01340863283940474,\n",
              "  -0.04164832419664432,\n",
              "  0.12541095927335225,\n",
              "  -0.025747487049223833,\n",
              "  0.020794780567579923,\n",
              "  0.01697517079462857,\n",
              "  -0.034040616111499424,\n",
              "  0.1355955152763015,\n",
              "  0.0838103332385057,\n",
              "  0.04561727608707208,\n",
              "  -0.1065061011656553,\n",
              "  0.07645279558189085,\n",
              "  0.10910261898567701,\n",
              "  0.021914199000333943,\n",
              "  0.08158261130362358,\n",
              "  0.09653150580860698,\n",
              "  -0.022001999403827993,\n",
              "  -0.0905363064972868,\n",
              "  -0.023552017701809008,\n",
              "  -0.11332638604984545,\n",
              "  -0.37205733160859766,\n",
              "  -0.05804096057580669,\n",
              "  -0.14673291149247977,\n",
              "  -0.14975960705216437,\n",
              "  -0.027903665786860377,\n",
              "  -0.022338378113785317,\n",
              "  -0.15362017919565837,\n",
              "  -0.2144895180927245,\n",
              "  -0.15379122299783668,\n",
              "  -0.22812676187877398,\n",
              "  -0.2593243315603406,\n",
              "  -0.1717278490106833,\n",
              "  -0.23589437533247745,\n",
              "  -0.2440581227622124,\n",
              "  -0.15889411320286534,\n",
              "  -0.1539137192375232,\n",
              "  -0.25062724295252314,\n",
              "  -0.21548737598680617,\n",
              "  -0.26849952455609355,\n",
              "  -0.23002037702858563,\n",
              "  -0.3045781748238248,\n",
              "  -0.26985892364780206,\n",
              "  -0.21221222309049578,\n",
              "  -0.22579305225449753,\n",
              "  -0.2660898091927772,\n",
              "  -0.2587595705378195,\n",
              "  -0.2541556393729441,\n",
              "  -0.24647793719652764,\n",
              "  -0.16314586619726665,\n",
              "  -0.19198530119346646,\n",
              "  -0.18945324242201447,\n",
              "  -0.1669516943082378,\n",
              "  -0.2675206800903845,\n",
              "  -0.23851390450811272,\n",
              "  -0.1659826842921523,\n",
              "  -0.16072969365527146,\n",
              "  -0.24983818086241008,\n",
              "  -0.3291969343774357,\n",
              "  -0.2101663792979533,\n",
              "  -0.2131814563465214,\n",
              "  -0.3685460586551227,\n",
              "  -0.2004851266570794,\n",
              "  -0.3539461342342129,\n",
              "  -0.2998682049236234,\n",
              "  -0.21372387901830708,\n",
              "  -0.2065462842253942,\n",
              "  -0.31181015450763533,\n",
              "  -0.1510776742306785,\n",
              "  0.1054601716221503,\n",
              "  -0.1490616577554475,\n",
              "  -0.011714533117017123,\n",
              "  -0.3248636269751282,\n",
              "  -0.18481846507659663,\n",
              "  0.0019105044423526959,\n",
              "  0.07440428317321364,\n",
              "  0.1863276554509428,\n",
              "  -0.13463943788241692,\n",
              "  1.6074079222455737,\n",
              "  -0.18322779825678068,\n",
              "  -0.6666423899835612,\n",
              "  -1.2370268945214047,\n",
              "  -0.45857638625060737,\n",
              "  1.542833976010576,\n",
              "  -0.8886585712284948,\n",
              "  0.15429523670752382,\n",
              "  0.6613894629800643,\n",
              "  0.006887943619878725,\n",
              "  -0.19772589487764755,\n",
              "  -0.08059512222844033,\n",
              "  -0.7946865689597229,\n",
              "  -0.08602835759175723,\n",
              "  -0.1895760177305268,\n",
              "  -0.24319928499745597,\n",
              "  -0.058061947032976007,\n",
              "  -0.12577040308624204,\n",
              "  -0.0594347913121559,\n",
              "  -0.7560699935678389,\n",
              "  -0.49955103958207303,\n",
              "  -0.12751325121772275,\n",
              "  -0.7629085936451142,\n",
              "  0.2442407407797425,\n",
              "  -0.1433771084633009,\n",
              "  -0.40220244508180847,\n",
              "  -0.16303915788241938,\n",
              "  -0.06345549878304865,\n",
              "  -0.5569238904168616,\n",
              "  0.34023841193372006,\n",
              "  -1.362472458084236,\n",
              "  -1.7013240921206607,\n",
              "  0.13115101550902908,\n",
              "  -1.6741987425411775,\n",
              "  -0.08518255416757847,\n",
              "  -1.2763668969836157,\n",
              "  -0.5660776858597416,\n",
              "  -1.7297149341301428,\n",
              "  -1.7090004821287013,\n",
              "  -0.50106628197308,\n",
              "  -0.1546733203028321,\n",
              "  -0.12656447516671854,\n",
              "  0.7649401524796602,\n",
              "  -0.5447922490400198,\n",
              "  1.275930912874855,\n",
              "  -0.17518480622593038,\n",
              "  0.7348711069291505,\n",
              "  -0.2506856175652283,\n",
              "  0.14838345856644183,\n",
              "  0.02918182454507601,\n",
              "  0.6667579443854222,\n",
              "  1.3448817385784135,\n",
              "  -0.2829127954729788,\n",
              "  0.7154985787744408,\n",
              "  -0.9229784394676701,\n",
              "  0.6104421519479298,\n",
              "  -0.918687440658222,\n",
              "  1.342321199539644,\n",
              "  1.5386989403730662,\n",
              "  -0.41969940837913094,\n",
              "  -0.07984641296973494,\n",
              "  1.064984024234985,\n",
              "  0.24060968642448718,\n",
              "  0.4646167371442047,\n",
              "  -0.4344440566115667,\n",
              "  -0.06907055121856225,\n",
              "  -0.4801583278841109,\n",
              "  0.9737362922547388,\n",
              "  1.0430847812233812,\n",
              "  -0.32041733931728594,\n",
              "  0.08829934038524509,\n",
              "  -0.8770895561670918,\n",
              "  0.4865920426103286,\n",
              "  -0.4438481096800119,\n",
              "  0.049300754565980806,\n",
              "  0.08168118414609034,\n",
              "  0.6593904659471156,\n",
              "  -0.8243081624571391,\n",
              "  -0.960456013117264,\n",
              "  0.14824532005827118,\n",
              "  -0.36879376205288966,\n",
              "  -0.6480709837437333,\n",
              "  0.6783987748557154,\n",
              "  -0.4167129618419788,\n",
              "  0.7014021074510245,\n",
              "  0.05408329173653009,\n",
              "  1.041358537693107,\n",
              "  0.2116406308120684,\n",
              "  1.1300867195253537,\n",
              "  -0.007341870048393863,\n",
              "  1.2096647310835926,\n",
              "  -0.21603077280654542,\n",
              "  1.4233057976311885,\n",
              "  -0.01788104993382545,\n",
              "  1.4018006239177816,\n",
              "  0.12301515414808091,\n",
              "  -0.06961593072862507,\n",
              "  -0.3834061879143928,\n",
              "  -0.6250674694932501,\n",
              "  -0.6942092565411466,\n",
              "  -0.6995497994162376,\n",
              "  -0.4154067674094874,\n",
              "  -0.18355765710742536,\n",
              "  -0.20795218736086635,\n",
              "  -0.7491291406577457,\n",
              "  0.22029819348770033,\n",
              "  -0.08333262880890563,\n",
              "  0.4883542146361166,\n",
              "  -0.12947809298248733,\n",
              "  -1.30288514075433,\n",
              "  0.5354664998125325,\n",
              "  -0.2067842427993941,\n",
              "  -0.08939470526970923,\n",
              "  -0.000284509673151629,\n",
              "  0.26332671053548,\n",
              "  0.43705663212253887,\n",
              "  0.4865604774569631,\n",
              "  0.48686587988217983,\n",
              "  -0.20937420391811198,\n",
              "  -0.19879633797800386,\n",
              "  -0.15671895053185073,\n",
              "  0.07896203503611167,\n",
              "  -0.04364607857870727,\n",
              "  2.303094029285122,\n",
              "  -0.9773259854534089,\n",
              "  0.12086928247999415,\n",
              "  -0.8206026810454349,\n",
              "  0.17364898151776836,\n",
              "  -0.8312336593998517,\n",
              "  -0.006495634528431647,\n",
              "  0.25257101947697574,\n",
              "  0.7691717603779074,\n",
              "  0.5510960359658017,\n",
              "  -0.18935913693040665,\n",
              "  0.7680307441222909,\n",
              "  1.2476247285742559,\n",
              "  0.6702602830020702,\n",
              "  0.47286216613814575,\n",
              "  1.2199891203322886,\n",
              "  -0.41603860476401516,\n",
              "  -0.6259785073680534,\n",
              "  0.31938012183157033,\n",
              "  0.3979824869005514,\n",
              "  0.2663659982557061,\n",
              "  0.08051247509712324,\n",
              "  -0.012047874025637935,\n",
              "  0.3595182739613707,\n",
              "  0.4240331052803447,\n",
              "  0.09223951194928477,\n",
              "  0.3416984475578845,\n",
              "  0.3344853349586691,\n",
              "  0.6486407842115913,\n",
              "  1.8593853724279017,\n",
              "  0.049419231953571605,\n",
              "  0.936902869581446,\n",
              "  -0.2665385121539631,\n",
              "  0.301289882564464,\n",
              "  1.747446791099041,\n",
              "  1.1341836392956315,\n",
              "  0.08409052392179833,\n",
              "  0.26900638888319456,\n",
              "  -0.04806365231141054,\n",
              "  1.7073734502537525,\n",
              "  1.5035252310942162,\n",
              "  0.26023275241931315,\n",
              "  1.6456476076739717,\n",
              "  0.14908263846285721,\n",
              "  1.681134361054029,\n",
              "  0.7324778890459654,\n",
              "  1.6290743334755322,\n",
              "  1.4493587017458938,\n",
              "  0.326440292890843,\n",
              "  0.002026794937529741,\n",
              "  0.24390417579527066,\n",
              "  -0.5916075683328252,\n",
              "  0.5226420684156798,\n",
              "  -1.4133598147711155,\n",
              "  0.0523986047104424,\n",
              "  -0.7946436239560607,\n",
              "  0.36624667227549257,\n",
              "  0.1435853637941919,\n",
              "  -0.17676884195473935,\n",
              "  -0.14371426212886934,\n",
              "  -0.1871232322518765,\n",
              "  0.21265935164517233,\n",
              "  -0.2952133729716777,\n",
              "  -0.27509562439826185,\n",
              "  -0.08540371197253785,\n",
              "  -0.28907342965293387,\n",
              "  -0.37212597213035564,\n",
              "  -0.3982774975361845,\n",
              "  -0.07641385107602239,\n",
              "  0.6031996064804886,\n",
              "  0.24657858812371222,\n",
              "  0.25843869009494513,\n",
              "  -0.014659829115564594,\n",
              "  -0.2971135046510801,\n",
              "  -0.3927415934008433,\n",
              "  -0.38102529650045963,\n",
              "  -0.3586983038132164,\n",
              "  -0.12210060231896218,\n",
              "  0.10682001616940758,\n",
              "  0.6489385642100335,\n",
              "  -0.5269845181120092,\n",
              "  -0.14534439705631313,\n",
              "  0.7100105692044084,\n",
              "  -0.09557045923931605,\n",
              "  -0.49798113667027794,\n",
              "  -0.1838110005060092,\n",
              "  0.9014645139336792,\n",
              "  0.015803875796438965,\n",
              "  -0.2722611330578988,\n",
              "  -0.3239117355914595,\n",
              "  -0.3616229327189903,\n",
              "  -0.19906572321689436,\n",
              "  0.5929434086454454,\n",
              "  2.251208375416113,\n",
              "  -0.35304687172430654,\n",
              "  -0.9846067784699376,\n",
              "  -1.6748812374177628,\n",
              "  -0.6809553823915611,\n",
              "  2.2357911125736396,\n",
              "  -1.035232762945307,\n",
              "  0.03798804653592035,\n",
              "  0.641234200453578,\n",
              "  0.02351059027125802,\n",
              "  -0.21018555373240488,\n",
              "  -0.11169609381572247,\n",
              "  -0.8171548953027856,\n",
              "  -0.0639821782311603,\n",
              "  -0.19920077618686405,\n",
              "  -0.24609920982347958,\n",
              "  -0.04489921759487052,\n",
              "  -0.1746520433318802,\n",
              "  -0.11606216735999898,\n",
              "  -0.7486478667225445,\n",
              "  -0.5227582619791663,\n",
              "  0.018757164051353435,\n",
              "  -0.6549963196193411,\n",
              "  0.32226070357737446,\n",
              "  -0.13874179576163984,\n",
              "  -0.44915276617174865,\n",
              "  -0.13770772836910133,\n",
              "  0.06424946369023818,\n",
              "  -0.37614588591156944,\n",
              "  0.37793625367545475,\n",
              "  -1.431444562786733,\n",
              "  -1.6969197061454522,\n",
              "  0.26795701494370555,\n",
              "  -1.5438301881175762,\n",
              "  -0.06837580489428076,\n",
              "  -1.4172793706622875,\n",
              "  -0.4077926090606153,\n",
              "  -1.7071119884568355,\n",
              "  -1.6847074351041633,\n",
              "  -0.41183744687078633,\n",
              "  -0.10719030875862351,\n",
              "  0.002773490908362823,\n",
              "  0.8503040200489537,\n",
              "  -0.4952163804702901,\n",
              "  1.5383371608621006,\n",
              "  -0.14015176913378197,\n",
              "  0.8125563777181475,\n",
              "  -0.13459667125656105,\n",
              "  0.288979912701125,\n",
              "  0.06005297547938319,\n",
              "  -0.08041761960760672,\n",
              "  -0.8148711244555263,\n",
              "  0.08566335984003104,\n",
              "  -0.09914597582711115,\n",
              "  -0.3321180515699181,\n",
              "  -0.3297915744301431,\n",
              "  -0.26978831718654184,\n",
              "  -0.20264291036234694,\n",
              "  -0.06035288088903018,\n",
              "  -0.057859185378741525,\n",
              "  -0.0185921030609625,\n",
              "  -0.14090568080399396,\n",
              "  -0.06758789468111603,\n",
              "  -0.0898713674864888,\n",
              "  -0.039182538569219764,\n",
              "  -0.11753497627880867,\n",
              "  -0.06849084745821116,\n",
              "  -0.14005590143874866,\n",
              "  -0.08415856511461156,\n",
              "  0.07744593752265307,\n",
              "  0.10298151497627335,\n",
              "  0.09507157340869088,\n",
              "  0.10382862814673997,\n",
              "  0.09406397541938248,\n",
              "  0.09611308762229463,\n",
              "  0.08797561761058757,\n",
              "  0.0881922372785616,\n",
              "  0.08209569592615767,\n",
              "  -0.044955382292346996,\n",
              "  0.15617063066473055,\n",
              "  -0.21837308380270784,\n",
              "  -0.07341539679820235,\n",
              "  -0.20054285521250886,\n",
              "  0.11658085274839888,\n",
              "  0.24028298438526344,\n",
              "  -0.1576731652653657,\n",
              "  0.1899588076889894,\n",
              "  -0.7575219880307383,\n",
              "  -0.3134172275308724,\n",
              "  -0.40235496996336745,\n",
              "  -0.3947020118252276,\n",
              "  -0.5948114131111876,\n",
              "  -0.24047735322815325,\n",
              "  -0.5455133779893432,\n",
              "  -0.15156737078638857,\n",
              "  -0.1022365373472772,\n",
              "  0.6870791233464872,\n",
              "  -0.1939433513144187,\n",
              "  0.0,\n",
              "  -0.23878236842595932,\n",
              "  1.8973692067615946,\n",
              "  -0.3766818237419272,\n",
              "  -0.34099382444641424,\n",
              "  -0.3914356647888244,\n",
              "  0.0,\n",
              "  -0.10504272669872286,\n",
              "  -0.22820930366632405,\n",
              "  -0.9963215295905491,\n",
              "  -0.41014828360172806,\n",
              "  -0.3181061219795814,\n",
              "  -0.05070506458192111,\n",
              "  -0.29736925305181533,\n",
              "  -0.449386113973497,\n",
              "  -0.14488807300966883,\n",
              "  0.6657908472555697,\n",
              "  0.08459937850630253,\n",
              "  0.959661053436335,\n",
              "  -0.3797655527831658,\n",
              "  0.0,\n",
              "  -0.024834390485387263,\n",
              "  0.3761726760931557,\n",
              "  -0.3719083472044943,\n",
              "  -0.015150645649052434,\n",
              "  -0.041522739926869986,\n",
              "  -0.2037685730811288,\n",
              "  -0.2153207161587227,\n",
              "  0.02747689318495918,\n",
              "  0.40382269161217804,\n",
              "  1.0263863188034574,\n",
              "  1.540820981723875,\n",
              "  -0.8311244545269132,\n",
              "  -0.5525134596893755,\n",
              "  0.360122212605311,\n",
              "  0.3609463164114795,\n",
              "  -0.5293678378669466,\n",
              "  -0.566063780828009,\n",
              "  -0.3200159403120134,\n",
              "  0.613382377753594,\n",
              "  -1.0521655726812695,\n",
              "  0.40036656752904415,\n",
              "  -0.20937425071587634,\n",
              "  -0.7332464903069221,\n",
              "  0.12245906352407299,\n",
              "  -0.055618520311182106,\n",
              "  -0.3461545766181381,\n",
              "  -0.5247241821062758,\n",
              "  -0.5619918177332694,\n",
              "  -0.5575122190817203,\n",
              "  -0.7397200085237949,\n",
              "  -0.2658511771325688,\n",
              "  0.48838492508397724,\n",
              "  -0.22728806407606006,\n",
              "  -0.7894939180977972,\n",
              "  0.337777410263725,\n",
              "  -0.42626176898508294,\n",
              "  0.98245124030806,\n",
              "  -0.5090476754570505,\n",
              "  0.5156780998480205,\n",
              "  0.052571202411964314,\n",
              "  -0.1984444909315517,\n",
              "  0.08295078354577305,\n",
              "  -1.2221226842408381,\n",
              "  0.16675092770235173,\n",
              "  -1.300761857198996,\n",
              "  0.23056707095689782,\n",
              "  -1.316091842994154,\n",
              "  0.2648258601392417,\n",
              "  -0.13364495665416104,\n",
              "  0.13186068553677846,\n",
              "  -0.7601177933790462,\n",
              "  -0.30896910373541575,\n",
              "  -0.4015415513096376,\n",
              "  -0.38802577235993146,\n",
              "  -0.44047274680837206,\n",
              "  -0.26083556860483753,\n",
              "  -0.5365918920343625,\n",
              "  -0.1408270392918472,\n",
              "  -0.15155517228236856,\n",
              "  -0.10223373963773744,\n",
              "  0.69845625687891,\n",
              "  -0.192761483282219,\n",
              "  0.0,\n",
              "  0.22982670169655306,\n",
              "  -1.7801650404214027,\n",
              "  -0.36401140113231895,\n",
              "  -0.34028654393272717,\n",
              "  0.3609539162420175,\n",
              "  0.0,\n",
              "  0.09592140905349181,\n",
              "  -0.15938723945633632,\n",
              "  0.6827272759522621,\n",
              "  -0.07321805377162031,\n",
              "  1.2336624219462113,\n",
              "  0.24417771410134492,\n",
              "  0.20219403717172776,\n",
              "  -0.1345820395526617,\n",
              "  -0.7275382988531657,\n",
              "  0.1695837578000912,\n",
              "  -0.36980452805372516,\n",
              "  -0.7896478341258241,\n",
              "  -0.14108223366397754,\n",
              "  -0.17012584424846952,\n",
              "  -0.14305935903684805,\n",
              "  -0.22748618105171373,\n",
              "  -0.9767560354732145,\n",
              "  -0.4104338539444053,\n",
              "  -0.3326475367348959,\n",
              "  -0.050596554818316826,\n",
              "  -0.2966042750940954,\n",
              "  -0.4405858927946635,\n",
              "  -0.14511435716823465,\n",
              "  -0.14092355932733455,\n",
              "  0.027680214676426906,\n",
              "  0.11923423708863752,\n",
              "  0.9556699776369441,\n",
              "  -0.36816939274377797,\n",
              "  0.0,\n",
              "  0.1608746721511861,\n",
              "  0.12565176315608662,\n",
              "  0.2906333472772323,\n",
              "  -0.014837904645513942,\n",
              "  -0.04149802833907189,\n",
              "  -0.20284778335385314,\n",
              "  -0.20443887655812473,\n",
              "  -0.16409018031573672,\n",
              "  -0.06404853634391872,\n",
              "  -0.15457007944668916,\n",
              "  -0.21901249845024973,\n",
              "  -0.2293708427830896,\n",
              "  -0.22760033546705474,\n",
              "  -0.2240155777768228,\n",
              "  -0.0776533818854199,\n",
              "  -0.08806635071828486,\n",
              "  -0.7668599760299756,\n",
              "  -0.08747864819182896,\n",
              "  -0.015567878144077648,\n",
              "  0.5472320280108942,\n",
              "  -0.576781517204645,\n",
              "  0.054831076444003486,\n",
              "  -0.21890592657512517,\n",
              "  -0.5542764652545032,\n",
              "  -1.5151627100868361,\n",
              "  -0.08424899982405018,\n",
              "  -0.019077878063799923,\n",
              "  -0.09014366845303488,\n",
              "  0.11712370017782367,\n",
              "  0.1455662795474296,\n",
              "  -0.03235812104522538,\n",
              "  0.4877186506913273,\n",
              "  0.20346079157242647,\n",
              "  0.6277801826846953,\n",
              "  0.04984995931146043,\n",
              "  -0.1851514244201652,\n",
              "  -0.18399889534856656,\n",
              "  -0.1891331281412635,\n",
              "  -0.17993346196725918,\n",
              "  -0.6639630127681899,\n",
              "  -0.4851461813242582,\n",
              "  -0.17317168877493894,\n",
              "  -0.15417943138412757,\n",
              "  -0.45688259836351514,\n",
              "  -0.10756187837300894,\n",
              "  -0.21357859040337324,\n",
              "  -0.12921100510223177,\n",
              "  0.1068115010241059,\n",
              "  -0.10381409293687967,\n",
              "  0.19480764825117466,\n",
              "  0.021649115091721603,\n",
              "  0.45887163117589913,\n",
              "  -0.06394122126882422,\n",
              "  0.4492717519352348,\n",
              "  -0.00971834151477421,\n",
              "  0.6278766927814157,\n",
              "  -0.0744011876254802,\n",
              "  0.7264730992433464,\n",
              "  0.0672256596425581,\n",
              "  0.7743081865299329,\n",
              "  0.14397490652331518,\n",
              "  0.39126180916956665,\n",
              "  -0.03882112572877894,\n",
              "  0.32340541749916063,\n",
              "  -0.10175730347665732,\n",
              "  0.2916704062986715,\n",
              "  -0.13635786451385032,\n",
              "  -0.05855628687624722,\n",
              "  0.17925598127958237,\n",
              "  0.37128943776142864,\n",
              "  0.36533413622059147,\n",
              "  0.28809628203274185,\n",
              "  -0.0685294910728662,\n",
              "  -0.05134001743194214,\n",
              "  -0.17012584424847038,\n",
              "  0.18928051773347654,\n",
              "  0.7713213319945748,\n",
              "  0.06366895393453062,\n",
              "  -0.21009810040337612,\n",
              "  3.898666956929735,\n",
              "  3.5979615991917293,\n",
              "  2.2179335752757203,\n",
              "  1.9595105795716359,\n",
              "  -0.3131326020432573,\n",
              "  -0.35022271656664605,\n",
              "  -0.08464717973094885,\n",
              "  -0.08464717973094885,\n",
              "  -0.08464717973094885,\n",
              "  -0.08533201859828617,\n",
              "  -0.04043008847813947,\n",
              "  -0.041813618190135377,\n",
              "  -0.09688661678529875,\n",
              "  -0.09927044811238228,\n",
              "  -0.10830315336975173,\n",
              "  -0.11045105754613077,\n",
              "  -0.04796011377111683,\n",
              "  -0.04796011377111683,\n",
              "  -0.04043008847813947,\n",
              "  -0.041813618190135377,\n",
              "  -0.04043008847813947,\n",
              "  -0.18602234934321524,\n",
              "  -0.04043008847813947,\n",
              "  -0.18602234934321524,\n",
              "  -0.052549761087980845,\n",
              "  -0.1023529775611455,\n",
              "  -0.052549761087980845,\n",
              "  -0.10572270145981134,\n",
              "  -0.447098393340296,\n",
              "  -0.49411946334584433,\n",
              "  -0.9792273668028799,\n",
              "  -1.0033312638225107,\n",
              "  -0.8112321593290351,\n",
              "  -0.8068104160426679,\n",
              "  2.855266202033413,\n",
              "  2.010582662146895,\n",
              "  1.5900416762335166,\n",
              "  1.3326646440949477,\n",
              "  -0.6784526315862336,\n",
              "  -0.046277849486385074,\n",
              "  -0.17361948201097083,\n",
              "  -0.1871954076044901,\n",
              "  -0.042455149639607885,\n",
              "  -0.05356586996966943,\n",
              "  -0.042455149639607885,\n",
              "  -0.05356586996966943,\n",
              "  -0.17396982012417156,\n",
              "  -0.18885132960217452,\n",
              "  -0.06440452865630963,\n",
              "  -0.08041927317992491,\n",
              "  -0.10828249478365848,\n",
              "  -0.10989802179529276,\n",
              "  -0.12014037496276468,\n",
              "  -0.12160623497853387,\n",
              "  -0.05144036709408326,\n",
              "  -0.05144036709408326,\n",
              "  -0.06440452865630963,\n",
              "  -0.08041927317992491,\n",
              "  -0.24176665833240016,\n",
              "  -0.25688616513589924,\n",
              "  -0.5052120819467582,\n",
              "  -0.5147305797110376,\n",
              "  -0.43065000596206243,\n",
              "  -0.43065000596206243,\n",
              "  1.7434440672524845,\n",
              "  1.0200942437469553,\n",
              "  -0.2778790836160448,\n",
              "  -0.40823638462280354,\n",
              "  -0.45706721574331133,\n",
              "  -0.15276765195822284,\n",
              "  -0.42190802064264227,\n",
              "  -0.1205526595744377,\n",
              "  -0.45706721574331133,\n",
              "  0.41860161588224565,\n",
              "  0.012843195883702248,\n",
              "  -0.1272354860022995,\n",
              "  -0.34643486965840303,\n",
              "  -0.08415856511461156,\n",
              "  -0.027543923099782607,\n",
              "  -0.22009479121453004,\n",
              "  -0.22526305590929985,\n",
              "  -0.1179350718589525,\n",
              "  -0.22760212847285904,\n",
              "  -0.4348219252781296,\n",
              "  -0.3181061219795814,\n",
              "  1.7139910751579521,\n",
              "  1.5723431790478586,\n",
              "  0.8127368393053069,\n",
              "  0.7059135068699826,\n",
              "  -0.6071574393044487,\n",
              "  -0.6320895187859922,\n",
              "  -0.09955433632966783,\n",
              "  -0.10044446830842932,\n",
              "  -0.2911651557707855,\n",
              "  -0.3159657086911427,\n",
              "  -0.34190663187123915,\n",
              "  -0.3649148927071451,\n",
              "  -0.16647000976435186,\n",
              "  -0.16719660971041053,\n",
              "  -0.09955433632966783,\n",
              "  -0.10044446830842932,\n",
              "  -0.1440702775477541,\n",
              "  -0.2005335194218187,\n",
              "  -0.371496506772644,\n",
              "  0.4174681281492109,\n",
              "  -0.15152550293457062,\n",
              "  0.0692586749465176,\n",
              "  -0.06310853216837942,\n",
              "  -0.6544132509795211,\n",
              "  0.6319563448036835,\n",
              "  -0.10125834870756925,\n",
              "  0.4017958049962142,\n",
              "  -0.5522228961037482,\n",
              "  0.6461589103981817,\n",
              "  -0.5507340075541183,\n",
              "  -1.1057489473136546,\n",
              "  -0.5571661676104885,\n",
              "  -0.0021122263173985025,\n",
              "  -0.672872113295218,\n",
              "  -0.010217971573172571,\n",
              "  -0.1800397444380222,\n",
              "  -0.39720382199882903,\n",
              "  -0.30720807836496167,\n",
              "  -0.33931957583133426,\n",
              "  -0.2819289315450604,\n",
              "  -0.5535513631092054,\n",
              "  -0.5870126881900752],\n",
              " [0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0.0,\n",
              "  0.25,\n",
              "  0.0,\n",
              "  0.25,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.0,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.375,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.0,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  0.75,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.125,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.25,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.25,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.5,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  ...],\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpvuI_G-RENF"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwqJ67ZKWcf1",
        "outputId": "f3c3fc2b-c9e4-4aad-ea26-cbb5357fa07f"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.10\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit\n",
            "done\n",
            "rdkit-2020.09.1 installation finished!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4X_tIFiBOj"
      },
      "source": [
        "# Define the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se8c-vUIRENG",
        "outputId": "4e86fd3f-5f4c-45cc-c65e-4872e3e1c11c"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyEncoder(nn.Module):\n",
        "    def __init__(self, hidden=64, heads=4, layers = 4, max_len = 250, vocab_size=45):\n",
        "        super(MyEncoder,self).__init__()\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden, nhead=heads,dim_feedforward=64, dropout=0.1)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
        "        \n",
        "        self.pos_embed = nn.Embedding(max_len+2, hidden)\n",
        "        \n",
        "        self.tok_embed = nn.Embedding(vocab_size, hidden)\n",
        "        \n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def forward(self, input, mask=None, bracket_mask=None):\n",
        "        tok_emb = self.tok_embed(input)  # (T,B,H)\n",
        "        # print(tok_emb)\n",
        "\n",
        "        # bracket_mask = None\n",
        "        # mask = None\n",
        "        if bracket_mask is None:\n",
        "          pos = torch.arange(0., self.max_len+2, dtype=torch.int).unsqueeze(1).to(device)\n",
        "        else:\n",
        "          \n",
        "          pos = torch.cumsum(bracket_mask, dim=0).to(device)\n",
        "          \n",
        "          # print(pos)\n",
        "        pos_emb = self.pos_embed(pos) # (T,B,H)\n",
        "        \n",
        "        emb = tok_emb + pos_emb\n",
        "        \n",
        "        hidden = self.transformer_encoder(emb,src_key_padding_mask = mask) # (T,B,H)\n",
        "        \n",
        "        return hidden\n",
        "\n",
        "import torch\n",
        "from pretrained_transformer.pretrain_trfm import TrfmSeq2seq\n",
        "from pretrained_transformer.build_vocab import WordVocab\n",
        "from pretrained_transformer.utils import split\n",
        "\n",
        "max_length = 250 # TODO dynamic padding\n",
        "\n",
        "pad_index = 0\n",
        "unk_index = 1\n",
        "eos_index = 2\n",
        "sos_index = 3\n",
        "mask_index = 4\n",
        "\n",
        "def get_inputs(sm):\n",
        "    seq_len = max_length+2\n",
        "    sm = sm.split()\n",
        "#     print(sm)\n",
        "    if len(sm)>max_length:\n",
        "        print('SMILES is too long ({:d})'.format(len(sm)))\n",
        "        sm = sm[:max_length//2]+sm[-max_length//2:]\n",
        "    ids = [vocab.stoi.get(token, unk_index) for token in sm]\n",
        "#     print(ids)\n",
        "    ids = [sos_index] + ids + [eos_index]\n",
        "\n",
        "    # Fill seg with zeros where brackets (try to exclude branches) \n",
        "    # TODO vectorize\n",
        "    in_bracket = 0\n",
        "    branches = []\n",
        "    for token in sm:\n",
        "      if token == '(':\n",
        "        in_bracket+=1\n",
        "      elif token == ')':\n",
        "        in_bracket-=1\n",
        "\n",
        "      if not in_bracket and token != '(' and token != ')':\n",
        "        branches.append(1)\n",
        "      else:\n",
        "        branches.append(0)\n",
        "\n",
        "    branches = [1] + branches + [1]\n",
        "    seg = [True]*len(ids)\n",
        "    padding = [pad_index]*(seq_len - len(ids))\n",
        "    bool_padding = [False]*(seq_len - len(ids))\n",
        "    ids.extend(padding), seg.extend(bool_padding), branches.extend(padding)\n",
        "    return ids, seg, branches\n",
        "\n",
        "def get_array(smiles):\n",
        "    x_id, x_seg, branches = [], [], []\n",
        "    for sm in smiles:\n",
        "        #print(sm)\n",
        "        a,b,c = get_inputs(split(sm))\n",
        "        x_id.append(a)\n",
        "        x_seg.append(b)\n",
        "        branches.append(c)\n",
        "    return torch.tensor(x_id), torch.tensor(x_seg), torch.tensor(branches)\n",
        "\n",
        "vocab = WordVocab.load_vocab('pretrained_transformer/vocab.pkl')\n",
        "trfm = MyEncoder().to(device)\n",
        "print('Total parameters:', sum(p.numel() for p in trfm.parameters()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total parameters: 119872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX8ZugKpiGwL"
      },
      "source": [
        "#nets.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "\n",
        "class UnitedNet(nn.Module):\n",
        "    def __init__(self, dense_dim, smiles_len, use_mord=True, use_mat=True, infer=False, dir_path=None, vis_thresh=0.2):\n",
        "        super(UnitedNet, self).__init__()\n",
        "        self.use_mord = use_mord\n",
        "        self.use_mat = use_mat\n",
        "        self.infer = infer\n",
        "        self.vis_thresh = vis_thresh\n",
        "        self.dir_path = dir_path\n",
        "        self.smiles_len = smiles_len\n",
        "        \n",
        "        if self.dir_path:\n",
        "            self.smile_out_f = open(os.path.join(self.dir_path, 'smiles.txt'), 'w')\n",
        "            self.weight_f = open(os.path.join(self.dir_path, 'weight.txt'), 'w')\n",
        "        \n",
        "        self.trfm = MyEncoder()#.to(device)#trfm.to(device)\n",
        "            \n",
        "\n",
        "        self.trfm_conv1 = nn.Conv1d(64, 64, kernel_size=3,padding=1)\n",
        "        self.trfm_pool = nn.MaxPool1d(3)\n",
        "        # self.trfm_pool = nn.Identity()\n",
        "        self.trfm_conv2 = nn.Conv1d(64, 128, kernel_size=3,padding=1)\n",
        "        self.trfm_fc = nn.Linear(128 * 28, self.smiles_len)\n",
        "        # self.trfm_fc = nn.Linear(128 * 252, 150)\n",
        "\n",
        "        self.trfm_dropout = nn.Dropout(0.05)\n",
        "        \n",
        "#         # PARAMS FOR CNN NET\n",
        "#         # Convolutionals\n",
        "#         self.conv_conv1 = nn.Conv1d(42, 64, kernel_size=5, padding=2)\n",
        "#         self.conv_pool = nn.MaxPool1d(5)\n",
        "#         self.conv_conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
        "#         self.relu = nn.ReLU()\n",
        "\n",
        "#         # Fully connected\n",
        "        \n",
        "#         self.conv_fc = nn.Linear(128*12, self.smiles_len)#self.smiles_len // 5 // 5 , 120)\n",
        "\n",
        "        # Batch norms\n",
        "        self.conv_batch_norm1 = nn.BatchNorm1d(64)\n",
        "        self.conv_batch_norm2 = nn.BatchNorm1d(128)\n",
        "        # # PARAMS FOR CNN NET\n",
        "        # # Convolutionals\n",
        "        # self.conv_conv1 = nn.Conv2d(1, 6, kernel_size=3) #smiles_len-2\n",
        "        # self.conv_pool = nn.MaxPool2d(2, 2) #smiles_len/2\n",
        "        # self.conv_conv2 = nn.Conv2d(6, 16, kernel_size=3) #smiles_len-2\n",
        "\n",
        "        # # Fully connected\n",
        "        # self.conv_fc = nn.Linear(16 * 9 * int(((self.smiles_len-2)/2 - 2)/2), self.smiles_len)\n",
        "\n",
        "        # # Batch norms\n",
        "        # self.conv_batch_norm1 = nn.BatchNorm2d(6)\n",
        "        # self.conv_batch_norm2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # PARAMS FOR DENSE NET\n",
        "        # Fully connected\n",
        "        if self.use_mord:\n",
        "            self.dense_fc1 = nn.Linear(dense_dim, 512)\n",
        "            self.dense_fc2 = nn.Linear(512, 128)\n",
        "            self.dense_fc3 = nn.Linear(128, 64)\n",
        "\n",
        "            # Batch norms\n",
        "            self.dense_batch_norm1 = nn.BatchNorm1d(512)\n",
        "            self.dense_batch_norm2 = nn.BatchNorm1d(128)\n",
        "            self.dense_batch_norm3 = nn.BatchNorm1d(64)\n",
        "\n",
        "            # Dropouts\n",
        "            self.dense_dropout = nn.Dropout()\n",
        "\n",
        "        # PARAMS FOR ATTENTION NET\n",
        "        if self.use_mat:\n",
        "            #self.att_fc = nn.Linear(256, 1)\n",
        "            self.att_fc = nn.Linear(self.smiles_len+42+64, 1)\n",
        "        else:\n",
        "            self.comb_fc_alt = nn.Linear(128, 1)\n",
        "\n",
        "        # PARAMS FOR COMBINED NET\n",
        "        if self.use_mord:\n",
        "            self.comb_fc = nn.Linear(self.smiles_len+64, 1)\n",
        "        else:\n",
        "            self.comb_fc = nn.Linear(self.smiles_len, 1)\n",
        "\n",
        "    def forward(self, x_non_mord, x_mord, x_mat, smiles=None, mask=None, branch_mask=None):\n",
        "        \n",
        "        trfm_x = self.trfm(torch.t(smiles), mask, torch.t(branch_mask)) \n",
        "        x = torch.transpose(trfm_x, 0,1) # (B,T,H)\n",
        "        \n",
        "#                 trfm_x*=mask[:,:,None]\n",
        "#         print(trfm_x)\n",
        "        \n",
        "        x = torch.transpose(x, -1,-2) # (B,R,T)\n",
        "        #print(x.shape)\n",
        "        x = self.trfm_conv1(x) # (B, 64, T)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        x = self.trfm_pool(x)\n",
        "        #print(x.shape)\n",
        "        x = self.trfm_conv2(x) # (B, 64, T)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        x = self.trfm_pool(x)\n",
        "        # print(x.view(x.size(0), -1).shape)\n",
        "        # print(x.shape)\n",
        "        x = self.trfm_dropout(self.trfm_fc(x.view(x.size(0), -1)))\n",
        "        if self.use_mat:\n",
        "            x_non_mord = F.sigmoid(x)\n",
        "        else:\n",
        "            x_non_mord = F.relu(x)\n",
        "#         # FORWARD CNN\n",
        "#         x_non_mord = torch.transpose(x_non_mord, -1,-2)\n",
        "\n",
        "#         x_non_mord = self.conv_conv1(x_non_mord)\n",
        "#         x_non_mord = self.conv_batch_norm1(x_non_mord)\n",
        "#         x_non_mord = F.relu(x_non_mord)\n",
        "#         x_non_mord = self.conv_pool(x_non_mord)\n",
        "\n",
        "#         x_non_mord = self.conv_conv2(x_non_mord)\n",
        "#         x_non_mord = self.conv_batch_norm2(x_non_mord)\n",
        "#         x_non_mord = F.relu(x_non_mord)\n",
        "#         x_non_mord = self.conv_pool(x_non_mord)\n",
        "\n",
        "#         # print(x_non_mord.shape)\n",
        "#         x_non_mord = x_non_mord.view(x_non_mord.size(0), -1)\n",
        "#         if self.use_mat:\n",
        "#             x_non_mord = F.sigmoid(self.conv_fc(x_non_mord))\n",
        "#         else:\n",
        "#             x_non_mord = F.relu(self.conv_fc(x_non_mord))\n",
        "\n",
        "        # FORWARD DENSE\n",
        "        if self.use_mord:\n",
        "            x_mord = F.relu(self.dense_fc1(x_mord))\n",
        "            x_mord = self.dense_batch_norm1(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "            x_mord = F.relu(self.dense_fc2(x_mord))\n",
        "            x_mord = self.dense_batch_norm2(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "            x_mord = F.relu(self.dense_fc3(x_mord))\n",
        "            x_mord = self.dense_batch_norm3(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "        # FORWARD ATTENTION\n",
        "        if self.use_mat:\n",
        "            x_mat = torch.bmm(x_mat.permute(0, 2, 1), x_non_mord.unsqueeze(-1)).squeeze(-1)\n",
        "            x_mat = torch.cat([x_mat, x_non_mord], dim=1)\n",
        "\n",
        "            if self.use_mord:\n",
        "                x_comb = torch.cat([x_mat, x_mord], dim=1)\n",
        "                probs = torch.sigmoid(self.att_fc(x_comb))\n",
        "                if self.infer:\n",
        "                    if not smiles:\n",
        "                        raise ValueError('Please input smiles')\n",
        "                    alphas = x_comb.cpu().detach().numpy().tolist()\n",
        "                    alphas = [\"\\t\".join([str(round(elem, 4)) for elem in seq]) for seq in alphas]\n",
        "                    prob_list = probs.cpu().detach().numpy().tolist()\n",
        "                    for smile, alpha, prob in zip(smiles, alphas, prob_list):\n",
        "                        if prob[0] > self.vis_thresh:\n",
        "                            self.weight_f.write(alpha + '\\n')\n",
        "                            self.smile_out_f.write(smile + '\\n')\n",
        "                return probs\n",
        "            else:\n",
        "                return torch.sigmoid(self.comb_fc(x_mat))\n",
        "        else:\n",
        "            if self.use_mord:\n",
        "                x_comb = torch.cat([x_non_mord, x_mord], dim=1)\n",
        "            else:\n",
        "                x_comb = x_non_mord\n",
        "            # print(x_comb.shape)\n",
        "            return torch.sigmoid(self.comb_fc(x_comb))\n",
        "\n",
        "    def __del__(self):\n",
        "        print('Closing files ...')\n",
        "        if hasattr(self, 'weight_f'):\n",
        "            self.weight_f.close()\n",
        "        if hasattr(self, 'smile_out_f'):\n",
        "            self.smile_out_f.close()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ_7ynBZikQb"
      },
      "source": [
        "# Metrics + utils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F9fMP8lizib"
      },
      "source": [
        "# metrics.py\n",
        "\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "THRESH = 0.2\n",
        "\n",
        "\n",
        "def auc(y_true, y_scores):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = y_scores.cpu().detach().numpy()\n",
        "    return metrics.roc_auc_score(y_true, y_scores)\n",
        "\n",
        "\n",
        "def auc_threshold(y_true, y_scores):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = y_scores.cpu().detach().numpy()\n",
        "    fpr, tpr, threshold = metrics.roc_curve(y_true, y_scores)\n",
        "    return metrics.auc(fpr, tpr)\n",
        "\n",
        "\n",
        "def get_score_obj(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = (y_scores.cpu().detach().numpy() + thresh).astype(np.int16)\n",
        "    return metrics.classification_report(y_true, y_scores, output_dict=True)\n",
        "\n",
        "\n",
        "def f1(y_true, y_scores):\n",
        "    score_obj = get_score_obj(y_true, y_scores)\n",
        "    return score_obj['weighted avg']['f1-score']\n",
        "\n",
        "# Metrics for benchmark\n",
        "\n",
        "\n",
        "def sensitivity(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = (y_scores.cpu().detach().numpy() + 1 - thresh).astype(np.int16)\n",
        "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_scores).ravel()\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "\n",
        "def specificity(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = (y_scores.cpu().detach().numpy() + 1 - thresh).astype(np.int16)\n",
        "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_scores).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = (y_scores.cpu().detach().numpy() + 1 - thresh).astype(np.int16)\n",
        "    return metrics.accuracy_score(y_true, y_scores)\n",
        "\n",
        "\n",
        "def mcc(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "    y_scores = (y_scores.cpu().detach().numpy() + 1 - thresh).astype(np.int16)\n",
        "    return metrics.matthews_corrcoef(y_true, y_scores)\n",
        "\n",
        "# METRICS FOR CV\n",
        "\n",
        "\n",
        "def auc_cv(y_true, y_scores):\n",
        "    return metrics.roc_auc_score(y_true, y_scores)\n",
        "\n",
        "\n",
        "def get_score_obj_cv(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = (y_scores + 1 - thresh).astype(np.int16)\n",
        "    return metrics.classification_report(y_true, y_scores, output_dict=True)\n",
        "\n",
        "\n",
        "def f1_cv(y_true, y_scores):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    score_obj = get_score_obj_cv(y_true, y_scores)\n",
        "    return score_obj['weighted avg']['f1-score']\n",
        "\n",
        "\n",
        "def class1_precision_cv(y_true, y_scores):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    score_obj = get_score_obj_cv(y_true, y_scores)\n",
        "    return score_obj['1.0']['precision']\n",
        "\n",
        "\n",
        "def class1_recall_cv(y_true, y_scores):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    score_obj = get_score_obj_cv(y_true, y_scores)\n",
        "    return score_obj['1.0']['recall']\n",
        "\n",
        "\n",
        "def sensitivity_cv(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = (y_scores + 1 - thresh).astype(np.int16)\n",
        "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_scores).ravel()\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "\n",
        "def specificity_cv(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = (y_scores + 1 - thresh).astype(np.int16)\n",
        "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_scores).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "\n",
        "def accuracy_cv(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = (y_scores + 1 - thresh).astype(np.int16)\n",
        "    return metrics.accuracy_score(y_true, y_scores)\n",
        "\n",
        "\n",
        "def mcc_cv(y_true, y_scores, thresh=THRESH):\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = (y_scores + 1 - thresh).astype(np.int16)\n",
        "    return metrics.matthews_corrcoef(y_true, y_scores)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UOufJAjInJ"
      },
      "source": [
        "#utils.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "def get_max_length(x):\n",
        "    return len(max(x, key=len))\n",
        "\n",
        "\n",
        "def pad_sequence(seq):\n",
        "    def _pad(_it, _max_len):\n",
        "        return [0] * (_max_len - len(_it)) + _it\n",
        "    padded = [_pad(it, get_max_length(seq)) for it in seq]\n",
        "    return padded\n",
        "\n",
        "\n",
        "def custom_collate(batch):\n",
        "    transposed = zip(*batch)\n",
        "    lst = []\n",
        "    for samples in transposed:\n",
        "        try:\n",
        "            if isinstance(samples[0], str) or isinstance(samples[0], unicode):\n",
        "                lst.append(samples)\n",
        "        except NameError:\n",
        "            if isinstance(samples[0], str):\n",
        "                lst.append(samples)\n",
        "        if isinstance(samples[0], int):\n",
        "            lst.append(torch.LongTensor(samples))\n",
        "        elif isinstance(samples[0], float):\n",
        "            lst.append(torch.DoubleTensor(samples))\n",
        "        elif isinstance(samples[0], list):\n",
        "            lst.append(torch.LongTensor(pad_sequence(samples)))\n",
        "    return lst\n",
        "\n",
        "\n",
        "def create_dir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "\n",
        "def save_pickle(obj, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def read_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "\n",
        "def save_model(model, model_dir_path, hash_code):\n",
        "    if not os.path.exists(model_dir_path):\n",
        "        os.makedirs(model_dir_path)\n",
        "    torch.save(model.state_dict(), \"{}/model_{}_{}\".format(model_dir_path, hash_code, \"BEST\"))\n",
        "    print('Save done!')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woNSUklii0cX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYXV4MVDsdQd",
        "outputId": "41d36965-a718-4cce-de9f-8e9a99bae5d7"
      },
      "source": [
        "!pip install tensorboard_logger"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard_logger) (7.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from tensorboard_logger) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboard_logger) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard_logger) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboard_logger) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->tensorboard_logger) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDb2M8H9llI-"
      },
      "source": [
        "#single_run.py\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorboard_logger\n",
        "from torch.utils.data import dataloader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "plt.switch_backend('agg')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#saved models\n",
        "models_path = '/content'\n",
        "\n",
        "def train_validate_united(train_dataset,\n",
        "                          val_dataset,\n",
        "                          train_device,\n",
        "                          val_device,\n",
        "                          use_mat,\n",
        "                          use_mord,\n",
        "                          opt_type,\n",
        "                          n_epoch,\n",
        "                          batch_size,\n",
        "                          metrics,\n",
        "                          hash_code,\n",
        "                          lr):\n",
        "    train_loader = dataloader.DataLoader(dataset=train_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         collate_fn=custom_collate,\n",
        "                                         shuffle=False)\n",
        "\n",
        "    val_loader = dataloader.DataLoader(dataset=val_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       collate_fn=custom_collate,\n",
        "                                       shuffle=False)\n",
        "    \n",
        "    #tensorflow_logger fix\n",
        "    #tensorboard_logger.clean_default_logger()\n",
        "    try:\n",
        "      tensorboard_logger.configure('logs/' + hash_code)\n",
        "    except Exception:\n",
        "      print('tensorboard_logger already configured!')\n",
        "    \n",
        "\n",
        "    sm, mord_ft, non_mord_ft, label = next(iter(train_loader))\n",
        "    smiles_len = int(non_mord_ft.shape[1]/42)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    united_net = UnitedNet(dense_dim=train_dataset.get_dim('mord'), smiles_len=smiles_len,\n",
        "                           use_mat=use_mat, use_mord=use_mord).to(train_device)\n",
        "\n",
        "    if opt_type == 'sgd':\n",
        "        opt = optim.SGD(united_net.parameters(),\n",
        "                        lr=lr,\n",
        "                        momentum=0.99)\n",
        "    elif opt_type == 'adam':\n",
        "        opt = optim.Adam(united_net.parameters(),\n",
        "                         lr=lr)\n",
        "\n",
        "    min_loss = 100  # arbitary large number\n",
        "    early_stop_count = 0\n",
        "    for e in range(n_epoch):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_outputs = []\n",
        "        val_outputs = []\n",
        "        train_labels = []\n",
        "        val_labels = []\n",
        "        print(e, '--', 'TRAINING ==============>')\n",
        "        for i, (sm, mord_ft, non_mord_ft, label) in enumerate(train_loader):\n",
        "            \n",
        "            sm, mask, br_mask = get_array(sm)\n",
        "            sm = sm.to(val_device)\n",
        "            mask = mask.to(val_device)\n",
        "            br_mask = br_mask.to(val_device)\n",
        "            \n",
        "            united_net.train()\n",
        "            mord_ft = mord_ft.float().to(train_device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(train_device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(train_device)\n",
        "            # print(label)\n",
        "            label = label.float().to(train_device)\n",
        "\n",
        "            # Forward\n",
        "            opt.zero_grad()\n",
        "            outputs = united_net(non_mord_ft, mord_ft, mat_ft, smiles = sm, mask=mask, branch_mask=br_mask)\n",
        "            \n",
        "            outputs = torch.squeeze(outputs)\n",
        "            \n",
        "            loss = criterion(outputs, label)\n",
        "            train_losses.append(float(loss.item()))\n",
        "            train_outputs.extend(outputs)\n",
        "            train_labels.extend(label)\n",
        "\n",
        "            # Parameters update\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        # Validate after each epoch\n",
        "        print('EPOCH', e, '--', 'VALIDATION ==============>')\n",
        "        for i, (sm, mord_ft, non_mord_ft, label) in enumerate(val_loader):\n",
        "            \n",
        "            \n",
        "            united_net.eval()\n",
        "            \n",
        "            sm, mask, br_mask = get_array(sm)\n",
        "            sm = sm.to(val_device)\n",
        "            mask = mask.to(val_device)\n",
        "            br_mask = br_mask.to(val_device)\n",
        "            \n",
        "            mord_ft = mord_ft.float().to(val_device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(val_device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(train_device)\n",
        "            label = label.float().to(val_device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = united_net(non_mord_ft, mord_ft, mat_ft, smiles=sm, mask=mask, branch_mask=br_mask)\n",
        "                \n",
        "                outputs = torch.squeeze(outputs)\n",
        "                \n",
        "                loss = criterion(outputs, label)\n",
        "                val_losses.append(float(loss.item()))\n",
        "                val_outputs.extend(outputs)\n",
        "                val_labels.extend(label)\n",
        "\n",
        "        train_outputs = torch.stack(train_outputs)\n",
        "        val_outputs = torch.stack(val_outputs)\n",
        "        train_labels = torch.stack(train_labels)\n",
        "        val_labels = torch.stack(val_labels)\n",
        "        tensorboard_logger.log_value('train_loss', sum(train_losses) / len(train_losses), e + 1)\n",
        "        tensorboard_logger.log_value('val_loss', sum(val_losses) / len(val_losses), e + 1)\n",
        "        print('{\"metric\": \"train_loss\", \"value\": %f, \"epoch\": %d}' % (sum(train_losses) / len(train_losses), e + 1))\n",
        "        print('{\"metric\": \"val_loss\", \"value\": %f, \"epoch\": %d}' % (sum(val_losses) / len(val_losses), e + 1))\n",
        "        for key in metrics.keys():\n",
        "            train_metric = metrics[key](train_labels, train_outputs)\n",
        "            val_metric = metrics[key](val_labels, val_outputs)\n",
        "            print('{\"metric\": \"%s\", \"value\": %f, \"epoch\": %d}' % ('train_' + key, train_metric, e + 1))\n",
        "            print('{\"metric\": \"%s\", \"value\": %f, \"epoch\": %d}' % ('val_' + key, val_metric, e + 1))\n",
        "            tensorboard_logger.log_value('train_{}'.format(key),\n",
        "                                         train_metric, e + 1)\n",
        "            tensorboard_logger.log_value('val_{}'.format(key),\n",
        "                                         val_metric, e + 1)\n",
        "        loss_epoch = sum(val_losses) / len(val_losses)\n",
        "        if loss_epoch < min_loss:\n",
        "            early_stop_count = 0\n",
        "            min_loss = loss_epoch\n",
        "            save_model(united_net, models_path, hash_code)\n",
        "        else:\n",
        "            early_stop_count += 1\n",
        "            if early_stop_count > 30:\n",
        "                print('Traning can not improve from epoch {}\\tBest loss: {}'.format(e, min_loss))\n",
        "                break\n",
        "\n",
        "    train_metrics = {}\n",
        "    val_metrics = {}\n",
        "    for key in metrics.keys():\n",
        "        train_metrics[key] = metrics[key](train_labels, train_outputs)\n",
        "        val_metrics[key] = metrics[key](val_labels, val_outputs)\n",
        "\n",
        "    return train_metrics, val_metrics\n",
        "\n",
        "\n",
        "def predict(dataset, model_path, device='cpu'):\n",
        "    loader = dataloader.DataLoader(dataset=dataset,\n",
        "                                   batch_size=128,\n",
        "                                   collate_fn=custom_collate,\n",
        "                                   shuffle=False)\n",
        "    \n",
        "    sm, mord_ft, non_mord_ft, label = next(iter(loader))\n",
        "    smiles_len = int(non_mord_ft.shape[1]/42)\n",
        "\n",
        "    united_net = UnitedNet(dense_dim=dataset.get_dim('mord'), smiles_len=smiles_len, use_mat=True).to(device)\n",
        "    united_net.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    # EVAL_MODE\n",
        "    united_net.eval()\n",
        "    probas = []\n",
        "    for i, (sm, mord_ft, non_mord_ft, label) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            sm, mask, br_mask = get_array(sm)\n",
        "            sm = sm.to(val_device)\n",
        "            mask = mask.to(val_device)\n",
        "            br_mask = br_mask.to(val_device)\n",
        "            \n",
        "            mord_ft = mord_ft.float().to(device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(device)\n",
        "            # Forward to get smiles and equivalent weights\n",
        "            proba = united_net(non_mord_ft, mord_ft, mat_ft).cpu()\n",
        "            probas.append(proba)\n",
        "    print('Forward done !!!')\n",
        "    probas = np.concatenate(probas)\n",
        "    return probas\n",
        "\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred, hashcode=''):\n",
        "\n",
        "    if not os.path.exists('vis/'):\n",
        "        os.makedirs('vis/')\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
        "    auc_roc = metrics.roc_auc_score(y_true, y_pred)\n",
        "    print('AUC: {:4f}'.format(auc_roc))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.savefig('vis/ROC_{}'.format(hashcode + '.png'))\n",
        "    plt.clf()  # Clear figure\n",
        "\n",
        "\n",
        "def plot_precision_recall(y_true, y_pred, hashcode=''):\n",
        "\n",
        "    if not os.path.exists('vis/'):\n",
        "        os.makedirs('vis/')\n",
        "\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    plt.plot(thresholds, precisions[:-1], label=\"Precision\")\n",
        "    plt.plot(thresholds, recalls[:-1], label=\"Recall\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylim([0, 1])\n",
        "    plt.savefig('vis/PR_{}'.format(hashcode + '.png'))\n",
        "    plt.clf()  # Clear figure\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    train_device = 'cuda'\n",
        "    val_device = 'cuda'\n",
        "else:\n",
        "    train_device = 'cpu'\n",
        "    val_device = 'cpu'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW4mDQNO_AAW",
        "outputId": "3f0b2ba3-558b-4550-bc7e-c4506562f729"
      },
      "source": [
        "#Hashcode for tf.events\n",
        "hashcode = 'TEST'\n",
        "\n",
        "train_validate_united(train_dataset,\n",
        "                      val_dataset,\n",
        "                      train_device,\n",
        "                      val_device,\n",
        "                      False, #Use mat feature (True) or not (False)\n",
        "                      False, #Use mord feature (True) or not (False)\n",
        "                      'adam', #Optimizer adam ('adam') or sgd ('sgd')\n",
        "                      int(500), #Number of epochs\n",
        "                      int(128), #Batch size\n",
        "                      {'sensitivity': sensitivity, 'specificity': specificity,\n",
        "                        'accuracy': accuracy, 'mcc': mcc, 'auc': auc},\n",
        "                      hashcode, #Hashcode for tf.events\n",
        "                      1e-5) #Learning rate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorboard_logger already configured!\n",
            "0 -- TRAINING ==============>\n",
            "Closing files ...\n",
            "Closing files ...\n",
            "Closing files ...\n",
            "Closing files ...\n",
            "EPOCH 0 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.605204, \"epoch\": 1}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.605946, \"epoch\": 1}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 1.000000, \"epoch\": 1}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 1}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.000000, \"epoch\": 1}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 1}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.269650, \"epoch\": 1}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 1}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.000000, \"epoch\": 1}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 1}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.491777, \"epoch\": 1}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.500636, \"epoch\": 1}\n",
            "Save done!\n",
            "1 -- TRAINING ==============>\n",
            "EPOCH 1 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.582091, \"epoch\": 2}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.603345, \"epoch\": 2}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 1.000000, \"epoch\": 2}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 2}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.000000, \"epoch\": 2}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 2}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.269650, \"epoch\": 2}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 2}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.000000, \"epoch\": 2}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 2}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.524918, \"epoch\": 2}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.540777, \"epoch\": 2}\n",
            "Save done!\n",
            "2 -- TRAINING ==============>\n",
            "EPOCH 2 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.580029, \"epoch\": 3}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.600880, \"epoch\": 3}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 1.000000, \"epoch\": 3}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 3}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.000000, \"epoch\": 3}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 3}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.269650, \"epoch\": 3}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 3}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.000000, \"epoch\": 3}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 3}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.548827, \"epoch\": 3}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.566480, \"epoch\": 3}\n",
            "Save done!\n",
            "3 -- TRAINING ==============>\n",
            "EPOCH 3 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.577926, \"epoch\": 4}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.598555, \"epoch\": 4}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.994894, \"epoch\": 4}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 4}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.005656, \"epoch\": 4}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 4}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.272404, \"epoch\": 4}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 4}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.003295, \"epoch\": 4}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 4}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.566397, \"epoch\": 4}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.580123, \"epoch\": 4}\n",
            "Save done!\n",
            "4 -- TRAINING ==============>\n",
            "EPOCH 4 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.575746, \"epoch\": 5}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.596422, \"epoch\": 5}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.987234, \"epoch\": 5}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 5}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.021053, \"epoch\": 5}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 5}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.281583, \"epoch\": 5}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 5}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.027063, \"epoch\": 5}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 5}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.580951, \"epoch\": 5}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.591981, \"epoch\": 5}\n",
            "Save done!\n",
            "5 -- TRAINING ==============>\n",
            "EPOCH 5 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.574194, \"epoch\": 6}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.594319, \"epoch\": 6}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.981277, \"epoch\": 6}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 6}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.029537, \"epoch\": 6}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 6}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.286173, \"epoch\": 6}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 6}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.029810, \"epoch\": 6}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 6}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.586399, \"epoch\": 6}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.604265, \"epoch\": 6}\n",
            "Save done!\n",
            "6 -- TRAINING ==============>\n",
            "EPOCH 6 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.572292, \"epoch\": 7}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.592052, \"epoch\": 7}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.977872, \"epoch\": 7}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 7}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.038178, \"epoch\": 7}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 7}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.291566, \"epoch\": 7}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 7}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.039386, \"epoch\": 7}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 7}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.592814, \"epoch\": 7}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.613945, \"epoch\": 7}\n",
            "Save done!\n",
            "7 -- TRAINING ==============>\n",
            "EPOCH 7 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.569543, \"epoch\": 8}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.589659, \"epoch\": 8}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.973191, \"epoch\": 8}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 1.000000, \"epoch\": 8}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.043362, \"epoch\": 8}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.000000, \"epoch\": 8}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.294091, \"epoch\": 8}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.272602, \"epoch\": 8}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.037993, \"epoch\": 8}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.000000, \"epoch\": 8}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.603344, \"epoch\": 8}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.622719, \"epoch\": 8}\n",
            "Save done!\n",
            "8 -- TRAINING ==============>\n",
            "EPOCH 8 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.567525, \"epoch\": 9}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.587226, \"epoch\": 9}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.970638, \"epoch\": 9}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.998316, \"epoch\": 9}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.048390, \"epoch\": 9}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.001893, \"epoch\": 9}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.297074, \"epoch\": 9}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.273520, \"epoch\": 9}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.041507, \"epoch\": 9}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.002177, \"epoch\": 9}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.606547, \"epoch\": 9}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.629870, \"epoch\": 9}\n",
            "Save done!\n",
            "9 -- TRAINING ==============>\n",
            "EPOCH 9 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.565241, \"epoch\": 10}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.584926, \"epoch\": 10}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.965957, \"epoch\": 10}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.989899, \"epoch\": 10}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.056245, \"epoch\": 10}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.006309, \"epoch\": 10}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.301549, \"epoch\": 10}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.274438, \"epoch\": 10}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.045099, \"epoch\": 10}\n",
            "{\"metric\": \"val_mcc\", \"value\": -0.019778, \"epoch\": 10}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.611605, \"epoch\": 10}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.635481, \"epoch\": 10}\n",
            "Save done!\n",
            "10 -- TRAINING ==============>\n",
            "EPOCH 10 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.563103, \"epoch\": 11}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.582784, \"epoch\": 11}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.962128, \"epoch\": 11}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 11}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.068028, \"epoch\": 11}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.010726, \"epoch\": 11}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.309122, \"epoch\": 11}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.276732, \"epoch\": 11}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.056396, \"epoch\": 11}\n",
            "{\"metric\": \"val_mcc\", \"value\": -0.011467, \"epoch\": 11}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.615692, \"epoch\": 11}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.639521, \"epoch\": 11}\n",
            "Save done!\n",
            "11 -- TRAINING ==============>\n",
            "EPOCH 11 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.560751, \"epoch\": 12}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.580767, \"epoch\": 12}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.949362, \"epoch\": 12}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 12}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.087353, \"epoch\": 12}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.014511, \"epoch\": 12}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.319793, \"epoch\": 12}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.279486, \"epoch\": 12}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.060952, \"epoch\": 12}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.003922, \"epoch\": 12}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.620480, \"epoch\": 12}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.643170, \"epoch\": 12}\n",
            "Save done!\n",
            "12 -- TRAINING ==============>\n",
            "EPOCH 12 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.559406, \"epoch\": 13}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.579287, \"epoch\": 13}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.945532, \"epoch\": 13}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 13}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.107463, \"epoch\": 13}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.015142, \"epoch\": 13}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.333448, \"epoch\": 13}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.279945, \"epoch\": 13}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.080908, \"epoch\": 13}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.006197, \"epoch\": 13}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.622294, \"epoch\": 13}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.647003, \"epoch\": 13}\n",
            "Save done!\n",
            "13 -- TRAINING ==============>\n",
            "EPOCH 13 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.557597, \"epoch\": 14}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.577665, \"epoch\": 14}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.934043, \"epoch\": 14}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 14}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.128672, \"epoch\": 14}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.018297, \"epoch\": 14}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.345841, \"epoch\": 14}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.282240, \"epoch\": 14}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.088334, \"epoch\": 14}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.016642, \"epoch\": 14}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.625922, \"epoch\": 14}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.650389, \"epoch\": 14}\n",
            "Save done!\n",
            "14 -- TRAINING ==============>\n",
            "EPOCH 14 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.555980, \"epoch\": 15}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.576439, \"epoch\": 15}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.923830, \"epoch\": 15}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 15}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.146269, \"epoch\": 15}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.018297, \"epoch\": 15}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.355938, \"epoch\": 15}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.282240, \"epoch\": 15}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.093310, \"epoch\": 15}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.016642, \"epoch\": 15}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.630444, \"epoch\": 15}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.652972, \"epoch\": 15}\n",
            "Save done!\n",
            "15 -- TRAINING ==============>\n",
            "EPOCH 15 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.555045, \"epoch\": 16}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.575407, \"epoch\": 16}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.914468, \"epoch\": 16}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 16}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.164022, \"epoch\": 16}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.020820, \"epoch\": 16}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.366380, \"epoch\": 16}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.284075, \"epoch\": 16}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.099541, \"epoch\": 16}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.024095, \"epoch\": 16}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.631388, \"epoch\": 16}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.655930, \"epoch\": 16}\n",
            "Save done!\n",
            "16 -- TRAINING ==============>\n",
            "EPOCH 16 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.554258, \"epoch\": 17}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.574355, \"epoch\": 17}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.903830, \"epoch\": 17}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.986532, \"epoch\": 17}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.172820, \"epoch\": 17}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.021451, \"epoch\": 17}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.369937, \"epoch\": 17}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.284534, \"epoch\": 17}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.094707, \"epoch\": 17}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.025855, \"epoch\": 17}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.632879, \"epoch\": 17}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.658341, \"epoch\": 17}\n",
            "Save done!\n",
            "17 -- TRAINING ==============>\n",
            "EPOCH 17 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.552653, \"epoch\": 18}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.573438, \"epoch\": 18}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.903404, \"epoch\": 18}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.983165, \"epoch\": 18}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.188060, \"epoch\": 18}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.029022, \"epoch\": 18}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.380952, \"epoch\": 18}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.289123, \"epoch\": 18}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.109783, \"epoch\": 18}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.034296, \"epoch\": 18}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.638822, \"epoch\": 18}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.660523, \"epoch\": 18}\n",
            "Save done!\n",
            "18 -- TRAINING ==============>\n",
            "EPOCH 18 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.552070, \"epoch\": 19}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.572663, \"epoch\": 19}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.895319, \"epoch\": 19}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.981481, \"epoch\": 19}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.201571, \"epoch\": 19}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.036593, \"epoch\": 19}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.388640, \"epoch\": 19}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.294172, \"epoch\": 19}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.113049, \"epoch\": 19}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.045963, \"epoch\": 19}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.638990, \"epoch\": 19}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.662346, \"epoch\": 19}\n",
            "Save done!\n",
            "19 -- TRAINING ==============>\n",
            "EPOCH 19 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.551115, \"epoch\": 20}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.571719, \"epoch\": 20}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.894043, \"epoch\": 20}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.976431, \"epoch\": 20}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.209584, \"epoch\": 20}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.042271, \"epoch\": 20}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.394148, \"epoch\": 20}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.296925, \"epoch\": 20}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.119277, \"epoch\": 20}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.044021, \"epoch\": 20}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.642376, \"epoch\": 20}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.663986, \"epoch\": 20}\n",
            "Save done!\n",
            "20 -- TRAINING ==============>\n",
            "EPOCH 20 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.550180, \"epoch\": 21}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.570962, \"epoch\": 21}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.884681, \"epoch\": 21}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.976431, \"epoch\": 21}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.218853, \"epoch\": 21}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.049211, \"epoch\": 21}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.398394, \"epoch\": 21}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.301973, \"epoch\": 21}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.116900, \"epoch\": 21}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.056782, \"epoch\": 21}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.644131, \"epoch\": 21}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.665127, \"epoch\": 21}\n",
            "Save done!\n",
            "21 -- TRAINING ==============>\n",
            "EPOCH 21 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.549439, \"epoch\": 22}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.570130, \"epoch\": 22}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.883404, \"epoch\": 22}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.971380, \"epoch\": 22}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.228123, \"epoch\": 22}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.061199, \"epoch\": 22}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.404819, \"epoch\": 22}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.309316, \"epoch\": 22}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.124189, \"epoch\": 22}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.065153, \"epoch\": 22}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.646177, \"epoch\": 22}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.666411, \"epoch\": 22}\n",
            "Save done!\n",
            "22 -- TRAINING ==============>\n",
            "EPOCH 22 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.548535, \"epoch\": 23}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.569614, \"epoch\": 23}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.878723, \"epoch\": 23}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.968013, \"epoch\": 23}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.239592, \"epoch\": 23}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.071293, \"epoch\": 23}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.411933, \"epoch\": 23}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.315741, \"epoch\": 23}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.129435, \"epoch\": 23}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.073372, \"epoch\": 23}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.649333, \"epoch\": 23}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.667335, \"epoch\": 23}\n",
            "Save done!\n",
            "23 -- TRAINING ==============>\n",
            "EPOCH 23 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.547910, \"epoch\": 24}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.568925, \"epoch\": 24}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.874894, \"epoch\": 24}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.959596, \"epoch\": 24}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.248233, \"epoch\": 24}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.082650, \"epoch\": 24}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.417212, \"epoch\": 24}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.321707, \"epoch\": 24}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.132996, \"epoch\": 24}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.073185, \"epoch\": 24}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.650105, \"epoch\": 24}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.668326, \"epoch\": 24}\n",
            "Save done!\n",
            "24 -- TRAINING ==============>\n",
            "EPOCH 24 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.547369, \"epoch\": 25}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.568211, \"epoch\": 25}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.874894, \"epoch\": 25}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.954545, \"epoch\": 25}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.252789, \"epoch\": 25}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.088328, \"epoch\": 25}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.420539, \"epoch\": 25}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.324461, \"epoch\": 25}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.137154, \"epoch\": 25}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.071767, \"epoch\": 25}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.652444, \"epoch\": 25}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.669404, \"epoch\": 25}\n",
            "Save done!\n",
            "25 -- TRAINING ==============>\n",
            "EPOCH 25 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.546442, \"epoch\": 26}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.567688, \"epoch\": 26}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.870638, \"epoch\": 26}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.946128, \"epoch\": 26}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.259230, \"epoch\": 26}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.094637, \"epoch\": 26}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.424096, \"epoch\": 26}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.326755, \"epoch\": 26}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.138188, \"epoch\": 26}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.065610, \"epoch\": 26}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.655176, \"epoch\": 26}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.670170, \"epoch\": 26}\n",
            "Save done!\n",
            "26 -- TRAINING ==============>\n",
            "EPOCH 26 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.545757, \"epoch\": 27}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.566981, \"epoch\": 27}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.866383, \"epoch\": 27}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.946128, \"epoch\": 27}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.268342, \"epoch\": 27}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.100315, \"epoch\": 27}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.429604, \"epoch\": 27}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.330886, \"epoch\": 27}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.141639, \"epoch\": 27}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.073132, \"epoch\": 27}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.656768, \"epoch\": 27}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.670782, \"epoch\": 27}\n",
            "Save done!\n",
            "27 -- TRAINING ==============>\n",
            "EPOCH 27 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.544926, \"epoch\": 28}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.566449, \"epoch\": 28}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.871915, \"epoch\": 28}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.939394, \"epoch\": 28}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.276041, \"epoch\": 28}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.112934, \"epoch\": 28}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.436718, \"epoch\": 28}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.338229, \"epoch\": 28}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.154598, \"epoch\": 28}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.078136, \"epoch\": 28}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.657918, \"epoch\": 28}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.671414, \"epoch\": 28}\n",
            "Save done!\n",
            "28 -- TRAINING ==============>\n",
            "EPOCH 28 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.544864, \"epoch\": 29}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.566041, \"epoch\": 29}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.864255, \"epoch\": 29}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.936027, \"epoch\": 29}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.280911, \"epoch\": 29}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.118612, \"epoch\": 29}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.438210, \"epoch\": 29}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.341441, \"epoch\": 29}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.150464, \"epoch\": 29}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.079800, \"epoch\": 29}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.658488, \"epoch\": 29}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.672178, \"epoch\": 29}\n",
            "Save done!\n",
            "29 -- TRAINING ==============>\n",
            "EPOCH 29 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.544205, \"epoch\": 30}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.565370, \"epoch\": 30}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.861277, \"epoch\": 30}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.934343, \"epoch\": 30}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.288610, \"epoch\": 30}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.125552, \"epoch\": 30}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.443029, \"epoch\": 30}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.346030, \"epoch\": 30}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.153985, \"epoch\": 30}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.085507, \"epoch\": 30}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.660070, \"epoch\": 30}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.673068, \"epoch\": 30}\n",
            "Save done!\n",
            "30 -- TRAINING ==============>\n",
            "EPOCH 30 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.543502, \"epoch\": 31}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.564818, \"epoch\": 31}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.857872, \"epoch\": 31}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.932660, \"epoch\": 31}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.290966, \"epoch\": 31}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.129968, \"epoch\": 31}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.443832, \"epoch\": 31}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.348784, \"epoch\": 31}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.152370, \"epoch\": 31}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.088124, \"epoch\": 31}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.661394, \"epoch\": 31}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.673583, \"epoch\": 31}\n",
            "Save done!\n",
            "31 -- TRAINING ==============>\n",
            "EPOCH 31 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.543092, \"epoch\": 32}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.564409, \"epoch\": 32}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.854894, \"epoch\": 32}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.930976, \"epoch\": 32}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.290495, \"epoch\": 32}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.134385, \"epoch\": 32}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.442685, \"epoch\": 32}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.351537, \"epoch\": 32}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.148748, \"epoch\": 32}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.090698, \"epoch\": 32}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.661235, \"epoch\": 32}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.674096, \"epoch\": 32}\n",
            "Save done!\n",
            "32 -- TRAINING ==============>\n",
            "EPOCH 32 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.542133, \"epoch\": 33}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.563926, \"epoch\": 33}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.854043, \"epoch\": 33}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.927609, \"epoch\": 33}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.304478, \"epoch\": 33}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.140694, \"epoch\": 33}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.452668, \"epoch\": 33}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.355209, \"epoch\": 33}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.160035, \"epoch\": 33}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.092908, \"epoch\": 33}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.664065, \"epoch\": 33}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.674637, \"epoch\": 33}\n",
            "Save done!\n",
            "33 -- TRAINING ==============>\n",
            "EPOCH 33 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.541665, \"epoch\": 34}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.563376, \"epoch\": 34}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.848511, \"epoch\": 34}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.925926, \"epoch\": 34}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.308248, \"epoch\": 34}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.143849, \"epoch\": 34}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.453930, \"epoch\": 34}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.357045, \"epoch\": 34}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.157442, \"epoch\": 34}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.094004, \"epoch\": 34}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.664589, \"epoch\": 34}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.675181, \"epoch\": 34}\n",
            "Save done!\n",
            "34 -- TRAINING ==============>\n",
            "EPOCH 34 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.541336, \"epoch\": 35}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.562970, \"epoch\": 35}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.847660, \"epoch\": 35}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.925926, \"epoch\": 35}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.309819, \"epoch\": 35}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.152681, \"epoch\": 35}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.454848, \"epoch\": 35}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.363469, \"epoch\": 35}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.157905, \"epoch\": 35}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.103660, \"epoch\": 35}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.665031, \"epoch\": 35}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.675747, \"epoch\": 35}\n",
            "Save done!\n",
            "35 -- TRAINING ==============>\n",
            "EPOCH 35 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.540819, \"epoch\": 36}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.562518, \"epoch\": 36}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.845957, \"epoch\": 36}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.922559, \"epoch\": 36}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.316732, \"epoch\": 36}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.157098, \"epoch\": 36}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.459438, \"epoch\": 36}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.365764, \"epoch\": 36}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.162086, \"epoch\": 36}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.103676, \"epoch\": 36}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.666372, \"epoch\": 36}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.676150, \"epoch\": 36}\n",
            "Save done!\n",
            "36 -- TRAINING ==============>\n",
            "EPOCH 36 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.540130, \"epoch\": 37}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.562115, \"epoch\": 37}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.846809, \"epoch\": 37}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.920875, \"epoch\": 37}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.320817, \"epoch\": 37}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.160883, \"epoch\": 37}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.462651, \"epoch\": 37}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.368059, \"epoch\": 37}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.166483, \"epoch\": 37}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.105367, \"epoch\": 37}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.668771, \"epoch\": 37}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.676767, \"epoch\": 37}\n",
            "Save done!\n",
            "37 -- TRAINING ==============>\n",
            "EPOCH 37 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.539433, \"epoch\": 38}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.561726, \"epoch\": 38}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.849362, \"epoch\": 38}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.919192, \"epoch\": 38}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.320817, \"epoch\": 38}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.170347, \"epoch\": 38}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.463339, \"epoch\": 38}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.374484, \"epoch\": 38}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.169149, \"epoch\": 38}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.112936, \"epoch\": 38}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.670121, \"epoch\": 38}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.676988, \"epoch\": 38}\n",
            "Save done!\n",
            "38 -- TRAINING ==============>\n",
            "EPOCH 38 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.538691, \"epoch\": 39}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.561323, \"epoch\": 39}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.841702, \"epoch\": 39}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.919192, \"epoch\": 39}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.329615, \"epoch\": 39}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.176025, \"epoch\": 39}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.467699, \"epoch\": 39}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.378614, \"epoch\": 39}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.168702, \"epoch\": 39}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.118721, \"epoch\": 39}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.670180, \"epoch\": 39}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.677434, \"epoch\": 39}\n",
            "Save done!\n",
            "39 -- TRAINING ==============>\n",
            "EPOCH 39 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.538393, \"epoch\": 40}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.560883, \"epoch\": 40}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.838298, \"epoch\": 40}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.917508, \"epoch\": 40}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.334171, \"epoch\": 40}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.177287, \"epoch\": 40}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.470109, \"epoch\": 40}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.379073, \"epoch\": 40}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.169080, \"epoch\": 40}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.117752, \"epoch\": 40}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.671482, \"epoch\": 40}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.678030, \"epoch\": 40}\n",
            "Save done!\n",
            "40 -- TRAINING ==============>\n",
            "EPOCH 40 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.537420, \"epoch\": 41}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.560411, \"epoch\": 41}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.837447, \"epoch\": 41}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.917508, \"epoch\": 41}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.336057, \"epoch\": 41}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.183596, \"epoch\": 41}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.471256, \"epoch\": 41}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.383662, \"epoch\": 41}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.169812, \"epoch\": 41}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.124065, \"epoch\": 41}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.673317, \"epoch\": 41}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.678634, \"epoch\": 41}\n",
            "Save done!\n",
            "41 -- TRAINING ==============>\n",
            "EPOCH 41 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.537019, \"epoch\": 42}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.560004, \"epoch\": 42}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.841702, \"epoch\": 42}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.915825, \"epoch\": 42}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.336371, \"epoch\": 42}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.188013, \"epoch\": 42}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.472633, \"epoch\": 42}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.386416, \"epoch\": 42}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.174449, \"epoch\": 42}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.126220, \"epoch\": 42}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.673982, \"epoch\": 42}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.678992, \"epoch\": 42}\n",
            "Save done!\n",
            "42 -- TRAINING ==============>\n",
            "EPOCH 42 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.536803, \"epoch\": 43}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.559603, \"epoch\": 43}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.840851, \"epoch\": 43}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.915825, \"epoch\": 43}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.342027, \"epoch\": 43}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.191798, \"epoch\": 43}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.476535, \"epoch\": 43}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.389169, \"epoch\": 43}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.178364, \"epoch\": 43}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.129921, \"epoch\": 43}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.673555, \"epoch\": 43}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.679514, \"epoch\": 43}\n",
            "Save done!\n",
            "43 -- TRAINING ==============>\n",
            "EPOCH 43 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.536247, \"epoch\": 44}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.559202, \"epoch\": 44}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.833617, \"epoch\": 44}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.912458, \"epoch\": 44}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.343441, \"epoch\": 44}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.194322, \"epoch\": 44}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.475617, \"epoch\": 44}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.390087, \"epoch\": 44}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.172178, \"epoch\": 44}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.128035, \"epoch\": 44}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.675431, \"epoch\": 44}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.679915, \"epoch\": 44}\n",
            "Save done!\n",
            "44 -- TRAINING ==============>\n",
            "EPOCH 44 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.535636, \"epoch\": 45}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.558794, \"epoch\": 45}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.831489, \"epoch\": 45}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.910774, \"epoch\": 45}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.349882, \"epoch\": 45}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.198107, \"epoch\": 45}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.479748, \"epoch\": 45}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.392382, \"epoch\": 45}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.175478, \"epoch\": 45}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.129554, \"epoch\": 45}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.676462, \"epoch\": 45}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.680426, \"epoch\": 45}\n",
            "Save done!\n",
            "45 -- TRAINING ==============>\n",
            "EPOCH 45 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.534951, \"epoch\": 46}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.558242, \"epoch\": 46}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.828085, \"epoch\": 46}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.902357, \"epoch\": 46}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.351296, \"epoch\": 46}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.205047, \"epoch\": 46}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.479862, \"epoch\": 46}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.395135, \"epoch\": 46}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.173235, \"epoch\": 46}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.125654, \"epoch\": 46}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.677661, \"epoch\": 46}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.680750, \"epoch\": 46}\n",
            "Save done!\n",
            "46 -- TRAINING ==============>\n",
            "EPOCH 46 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.533929, \"epoch\": 47}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.557937, \"epoch\": 47}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.835745, \"epoch\": 47}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.900673, \"epoch\": 47}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.361351, \"epoch\": 47}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.212618, \"epoch\": 47}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.489271, \"epoch\": 47}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.400184, \"epoch\": 47}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.189424, \"epoch\": 47}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.130823, \"epoch\": 47}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.679253, \"epoch\": 47}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.681247, \"epoch\": 47}\n",
            "Save done!\n",
            "47 -- TRAINING ==============>\n",
            "EPOCH 47 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.533810, \"epoch\": 48}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.557427, \"epoch\": 48}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.826809, \"epoch\": 48}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.897306, \"epoch\": 48}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.360723, \"epoch\": 48}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.211356, \"epoch\": 48}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.486403, \"epoch\": 48}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.398348, \"epoch\": 48}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.179918, \"epoch\": 48}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.125477, \"epoch\": 48}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.679060, \"epoch\": 48}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.681777, \"epoch\": 48}\n",
            "Save done!\n",
            "48 -- TRAINING ==============>\n",
            "EPOCH 48 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.533106, \"epoch\": 49}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.557021, \"epoch\": 49}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.834468, \"epoch\": 49}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.897306, \"epoch\": 49}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.364179, \"epoch\": 49}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.221451, \"epoch\": 49}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.490993, \"epoch\": 49}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.405691, \"epoch\": 49}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.190505, \"epoch\": 49}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.135052, \"epoch\": 49}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.681395, \"epoch\": 49}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.682299, \"epoch\": 49}\n",
            "Save done!\n",
            "49 -- TRAINING ==============>\n",
            "EPOCH 49 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.533529, \"epoch\": 50}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.556625, \"epoch\": 50}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.830638, \"epoch\": 50}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.895623, \"epoch\": 50}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.361822, \"epoch\": 50}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.226498, \"epoch\": 50}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.488239, \"epoch\": 50}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.408903, \"epoch\": 50}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.184685, \"epoch\": 50}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.137736, \"epoch\": 50}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.679813, \"epoch\": 50}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.682934, \"epoch\": 50}\n",
            "Save done!\n",
            "50 -- TRAINING ==============>\n",
            "EPOCH 50 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.532826, \"epoch\": 51}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.556209, \"epoch\": 51}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.826809, \"epoch\": 51}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.893939, \"epoch\": 51}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.367636, \"epoch\": 51}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.231546, \"epoch\": 51}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.491452, \"epoch\": 51}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.412116, \"epoch\": 51}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.185731, \"epoch\": 51}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.140401, \"epoch\": 51}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.681126, \"epoch\": 51}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.683575, \"epoch\": 51}\n",
            "Save done!\n",
            "51 -- TRAINING ==============>\n",
            "EPOCH 51 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.532054, \"epoch\": 52}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.555883, \"epoch\": 52}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.824681, \"epoch\": 52}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.893939, \"epoch\": 52}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.375177, \"epoch\": 52}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.232808, \"epoch\": 52}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.496386, \"epoch\": 52}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.413034, \"epoch\": 52}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.189932, \"epoch\": 52}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.141565, \"epoch\": 52}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.682694, \"epoch\": 52}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.684146, \"epoch\": 52}\n",
            "Save done!\n",
            "52 -- TRAINING ==============>\n",
            "EPOCH 52 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.531220, \"epoch\": 53}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.555478, \"epoch\": 53}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.824681, \"epoch\": 53}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.893939, \"epoch\": 53}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.370463, \"epoch\": 53}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.237855, \"epoch\": 53}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.492943, \"epoch\": 53}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.416705, \"epoch\": 53}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.185983, \"epoch\": 53}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.146194, \"epoch\": 53}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.683670, \"epoch\": 53}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.684486, \"epoch\": 53}\n",
            "Save done!\n",
            "53 -- TRAINING ==============>\n",
            "EPOCH 53 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.530764, \"epoch\": 54}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.555124, \"epoch\": 54}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.825532, \"epoch\": 54}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.893939, \"epoch\": 54}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.377219, \"epoch\": 54}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.242902, \"epoch\": 54}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.498107, \"epoch\": 54}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.420376, \"epoch\": 54}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.192483, \"epoch\": 54}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.150778, \"epoch\": 54}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.685335, \"epoch\": 54}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.685179, \"epoch\": 54}\n",
            "Save done!\n",
            "54 -- TRAINING ==============>\n",
            "EPOCH 54 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.530532, \"epoch\": 55}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.554771, \"epoch\": 55}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.818723, \"epoch\": 55}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.890572, \"epoch\": 55}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.377533, \"epoch\": 55}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.252366, \"epoch\": 55}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.496500, \"epoch\": 55}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.426342, \"epoch\": 55}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.186008, \"epoch\": 55}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.155355, \"epoch\": 55}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.685495, \"epoch\": 55}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.685639, \"epoch\": 55}\n",
            "Save done!\n",
            "55 -- TRAINING ==============>\n",
            "EPOCH 55 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.529717, \"epoch\": 56}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.554301, \"epoch\": 56}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.820851, \"epoch\": 56}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.892256, \"epoch\": 56}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.382090, \"epoch\": 56}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.250473, \"epoch\": 56}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.500402, \"epoch\": 56}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.425425, \"epoch\": 56}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.191924, \"epoch\": 56}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.155617, \"epoch\": 56}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.686974, \"epoch\": 56}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.686272, \"epoch\": 56}\n",
            "Save done!\n",
            "56 -- TRAINING ==============>\n",
            "EPOCH 56 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.528945, \"epoch\": 57}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.554046, \"epoch\": 57}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.825106, \"epoch\": 57}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.892256, \"epoch\": 57}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.387745, \"epoch\": 57}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.255521, \"epoch\": 57}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.505680, \"epoch\": 57}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.429096, \"epoch\": 57}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.200832, \"epoch\": 57}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.160114, \"epoch\": 57}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.687756, \"epoch\": 57}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.686768, \"epoch\": 57}\n",
            "Save done!\n",
            "57 -- TRAINING ==============>\n",
            "EPOCH 57 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.528525, \"epoch\": 58}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.553537, \"epoch\": 58}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.816596, \"epoch\": 58}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.885522, \"epoch\": 58}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.387745, \"epoch\": 58}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.259306, \"epoch\": 58}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.503385, \"epoch\": 58}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.430014, \"epoch\": 58}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.192465, \"epoch\": 58}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.155728, \"epoch\": 58}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.688450, \"epoch\": 58}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.687480, \"epoch\": 58}\n",
            "Save done!\n",
            "58 -- TRAINING ==============>\n",
            "EPOCH 58 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.527565, \"epoch\": 59}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.553024, \"epoch\": 59}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.822553, \"epoch\": 59}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.882155, \"epoch\": 59}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.389317, \"epoch\": 59}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.264984, \"epoch\": 59}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.506139, \"epoch\": 59}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.433226, \"epoch\": 59}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.199626, \"epoch\": 59}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.156936, \"epoch\": 59}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.690174, \"epoch\": 59}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.687906, \"epoch\": 59}\n",
            "Save done!\n",
            "59 -- TRAINING ==============>\n",
            "EPOCH 59 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.527177, \"epoch\": 60}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.552649, \"epoch\": 60}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.821702, \"epoch\": 60}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.878788, \"epoch\": 60}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.391673, \"epoch\": 60}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.268139, \"epoch\": 60}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.507631, \"epoch\": 60}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.434603, \"epoch\": 60}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.200750, \"epoch\": 60}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.155926, \"epoch\": 60}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.690855, \"epoch\": 60}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.688600, \"epoch\": 60}\n",
            "Save done!\n",
            "60 -- TRAINING ==============>\n",
            "EPOCH 60 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.526785, \"epoch\": 61}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.552367, \"epoch\": 61}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.816170, \"epoch\": 61}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.878788, \"epoch\": 61}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.397486, \"epoch\": 61}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.270662, \"epoch\": 61}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.510384, \"epoch\": 61}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.436439, \"epoch\": 61}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.200175, \"epoch\": 61}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.158158, \"epoch\": 61}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.691506, \"epoch\": 61}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.689151, \"epoch\": 61}\n",
            "Save done!\n",
            "61 -- TRAINING ==============>\n",
            "EPOCH 61 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.526181, \"epoch\": 62}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.551962, \"epoch\": 62}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.812766, \"epoch\": 62}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.873737, \"epoch\": 62}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.395758, \"epoch\": 62}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.274448, \"epoch\": 62}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.508204, \"epoch\": 62}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.437816, \"epoch\": 62}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.195414, \"epoch\": 62}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.155847, \"epoch\": 62}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.693136, \"epoch\": 62}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.689821, \"epoch\": 62}\n",
            "Save done!\n",
            "62 -- TRAINING ==============>\n",
            "EPOCH 62 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.525357, \"epoch\": 63}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.551540, \"epoch\": 63}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.817021, \"epoch\": 63}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.875421, \"epoch\": 63}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.399372, \"epoch\": 63}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.275710, \"epoch\": 63}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.511991, \"epoch\": 63}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.439192, \"epoch\": 63}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.202573, \"epoch\": 63}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.158837, \"epoch\": 63}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.694165, \"epoch\": 63}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.690400, \"epoch\": 63}\n",
            "Save done!\n",
            "63 -- TRAINING ==============>\n",
            "EPOCH 63 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.525159, \"epoch\": 64}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.551031, \"epoch\": 64}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.815319, \"epoch\": 64}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.875421, \"epoch\": 64}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.405970, \"epoch\": 64}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.278864, \"epoch\": 64}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.516351, \"epoch\": 64}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.441487, \"epoch\": 64}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.206401, \"epoch\": 64}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.161607, \"epoch\": 64}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.694136, \"epoch\": 64}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.690995, \"epoch\": 64}\n",
            "Save done!\n",
            "64 -- TRAINING ==============>\n",
            "EPOCH 64 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.524321, \"epoch\": 65}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.550589, \"epoch\": 65}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.817872, \"epoch\": 65}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.875421, \"epoch\": 65}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.402671, \"epoch\": 65}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.282019, \"epoch\": 65}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.514630, \"epoch\": 65}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.443782, \"epoch\": 65}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.206143, \"epoch\": 65}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.164366, \"epoch\": 65}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.695652, \"epoch\": 65}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.691747, \"epoch\": 65}\n",
            "Save done!\n",
            "65 -- TRAINING ==============>\n",
            "EPOCH 65 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.523750, \"epoch\": 66}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.550120, \"epoch\": 66}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 66}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.872054, \"epoch\": 66}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.405813, \"epoch\": 66}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.285804, \"epoch\": 66}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.514859, \"epoch\": 66}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.445617, \"epoch\": 66}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.201319, \"epoch\": 66}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.163948, \"epoch\": 66}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.695677, \"epoch\": 66}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.692334, \"epoch\": 66}\n",
            "Save done!\n",
            "66 -- TRAINING ==============>\n",
            "EPOCH 66 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.522937, \"epoch\": 67}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.549687, \"epoch\": 67}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.814894, \"epoch\": 67}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.872054, \"epoch\": 67}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.406756, \"epoch\": 67}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.283912, \"epoch\": 67}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.516810, \"epoch\": 67}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.444240, \"epoch\": 67}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.206640, \"epoch\": 67}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.162296, \"epoch\": 67}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.697852, \"epoch\": 67}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.692898, \"epoch\": 67}\n",
            "Save done!\n",
            "67 -- TRAINING ==============>\n",
            "EPOCH 67 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.522455, \"epoch\": 68}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.549231, \"epoch\": 68}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.811064, \"epoch\": 68}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.870370, \"epoch\": 68}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.413354, \"epoch\": 68}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.288328, \"epoch\": 68}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.520597, \"epoch\": 68}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.446994, \"epoch\": 68}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.208415, \"epoch\": 68}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.164296, \"epoch\": 68}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.698653, \"epoch\": 68}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.693448, \"epoch\": 68}\n",
            "Save done!\n",
            "68 -- TRAINING ==============>\n",
            "EPOCH 68 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.522148, \"epoch\": 69}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.548782, \"epoch\": 69}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.818298, \"epoch\": 69}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.870370, \"epoch\": 69}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.412883, \"epoch\": 69}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.293375, \"epoch\": 69}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.522203, \"epoch\": 69}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.450665, \"epoch\": 69}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.215016, \"epoch\": 69}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.168676, \"epoch\": 69}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.699680, \"epoch\": 69}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.694228, \"epoch\": 69}\n",
            "Save done!\n",
            "69 -- TRAINING ==============>\n",
            "EPOCH 69 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.521123, \"epoch\": 70}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.548284, \"epoch\": 70}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.814043, \"epoch\": 70}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.870370, \"epoch\": 70}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.419639, \"epoch\": 70}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.294637, \"epoch\": 70}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.525990, \"epoch\": 70}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.451583, \"epoch\": 70}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.216497, \"epoch\": 70}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.169767, \"epoch\": 70}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.701627, \"epoch\": 70}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.694784, \"epoch\": 70}\n",
            "Save done!\n",
            "70 -- TRAINING ==============>\n",
            "EPOCH 70 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.520622, \"epoch\": 71}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.547975, \"epoch\": 71}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.811915, \"epoch\": 71}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.867003, \"epoch\": 71}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.416496, \"epoch\": 71}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.299054, \"epoch\": 71}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.523121, \"epoch\": 71}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.453878, \"epoch\": 71}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.211844, \"epoch\": 71}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.169919, \"epoch\": 71}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.701145, \"epoch\": 71}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.695333, \"epoch\": 71}\n",
            "Save done!\n",
            "71 -- TRAINING ==============>\n",
            "EPOCH 71 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.520151, \"epoch\": 72}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.547356, \"epoch\": 72}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.812766, \"epoch\": 72}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.868687, \"epoch\": 72}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.420424, \"epoch\": 72}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.297161, \"epoch\": 72}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.526219, \"epoch\": 72}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.452960, \"epoch\": 72}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.215918, \"epoch\": 72}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.170113, \"epoch\": 72}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.703321, \"epoch\": 72}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.695957, \"epoch\": 72}\n",
            "Save done!\n",
            "72 -- TRAINING ==============>\n",
            "EPOCH 72 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.519829, \"epoch\": 73}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.547049, \"epoch\": 73}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 73}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.861953, \"epoch\": 73}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.422310, \"epoch\": 73}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.305994, \"epoch\": 73}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.526908, \"epoch\": 73}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.457549, \"epoch\": 73}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.215027, \"epoch\": 73}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.170453, \"epoch\": 73}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.702802, \"epoch\": 73}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.696609, \"epoch\": 73}\n",
            "Save done!\n",
            "73 -- TRAINING ==============>\n",
            "EPOCH 73 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.518701, \"epoch\": 74}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.546505, \"epoch\": 74}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.811489, \"epoch\": 74}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.863636, \"epoch\": 74}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.423723, \"epoch\": 74}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.307886, \"epoch\": 74}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.528285, \"epoch\": 74}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.459385, \"epoch\": 74}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.217424, \"epoch\": 74}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.173884, \"epoch\": 74}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.705146, \"epoch\": 74}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.697106, \"epoch\": 74}\n",
            "Save done!\n",
            "74 -- TRAINING ==============>\n",
            "EPOCH 74 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.518251, \"epoch\": 75}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.546178, \"epoch\": 75}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809362, \"epoch\": 75}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.863636, \"epoch\": 75}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.422152, \"epoch\": 75}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.310410, \"epoch\": 75}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.526563, \"epoch\": 75}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.461221, \"epoch\": 75}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.214079, \"epoch\": 75}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.176045, \"epoch\": 75}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.705030, \"epoch\": 75}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.697594, \"epoch\": 75}\n",
            "Save done!\n",
            "75 -- TRAINING ==============>\n",
            "EPOCH 75 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.518233, \"epoch\": 76}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.545818, \"epoch\": 76}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.807234, \"epoch\": 76}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.863636, \"epoch\": 76}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.424509, \"epoch\": 76}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.311041, \"epoch\": 76}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.527711, \"epoch\": 76}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.461680, \"epoch\": 76}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.213995, \"epoch\": 76}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.176584, \"epoch\": 76}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.705401, \"epoch\": 76}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.698339, \"epoch\": 76}\n",
            "Save done!\n",
            "76 -- TRAINING ==============>\n",
            "EPOCH 76 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.517740, \"epoch\": 77}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.545468, \"epoch\": 77}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809787, \"epoch\": 77}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.863636, \"epoch\": 77}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.425923, \"epoch\": 77}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.316088, \"epoch\": 77}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.529432, \"epoch\": 77}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.465351, \"epoch\": 77}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.217613, \"epoch\": 77}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.180885, \"epoch\": 77}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.706731, \"epoch\": 77}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.698935, \"epoch\": 77}\n",
            "Save done!\n",
            "77 -- TRAINING ==============>\n",
            "EPOCH 77 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.516215, \"epoch\": 78}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.544998, \"epoch\": 78}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.814043, \"epoch\": 78}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.860269, \"epoch\": 78}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.432993, \"epoch\": 78}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.324921, \"epoch\": 78}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.535743, \"epoch\": 78}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.470858, \"epoch\": 78}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.227533, \"epoch\": 78}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.184803, \"epoch\": 78}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.710476, \"epoch\": 78}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.699524, \"epoch\": 78}\n",
            "Save done!\n",
            "78 -- TRAINING ==============>\n",
            "EPOCH 78 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.515784, \"epoch\": 79}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.544653, \"epoch\": 79}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809362, \"epoch\": 79}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.860269, \"epoch\": 79}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.436135, \"epoch\": 79}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.326183, \"epoch\": 79}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.536776, \"epoch\": 79}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.471776, \"epoch\": 79}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.225661, \"epoch\": 79}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.185870, \"epoch\": 79}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.709641, \"epoch\": 79}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.700092, \"epoch\": 79}\n",
            "Save done!\n",
            "79 -- TRAINING ==============>\n",
            "EPOCH 79 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.514635, \"epoch\": 80}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.544207, \"epoch\": 80}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.816596, \"epoch\": 80}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.855219, \"epoch\": 80}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.435978, \"epoch\": 80}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.331230, \"epoch\": 80}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.538612, \"epoch\": 80}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.474071, \"epoch\": 80}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.232436, \"epoch\": 80}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.184831, \"epoch\": 80}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.711956, \"epoch\": 80}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.700630, \"epoch\": 80}\n",
            "Save done!\n",
            "80 -- TRAINING ==============>\n",
            "EPOCH 80 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.514244, \"epoch\": 81}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.543712, \"epoch\": 81}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.805106, \"epoch\": 81}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.855219, \"epoch\": 81}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.435192, \"epoch\": 81}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.335647, \"epoch\": 81}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.534940, \"epoch\": 81}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.477283, \"epoch\": 81}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.220826, \"epoch\": 81}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.188556, \"epoch\": 81}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.712898, \"epoch\": 81}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.701105, \"epoch\": 81}\n",
            "Save done!\n",
            "81 -- TRAINING ==============>\n",
            "EPOCH 81 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.513349, \"epoch\": 82}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.543459, \"epoch\": 82}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810638, \"epoch\": 82}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.856902, \"epoch\": 82}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.438492, \"epoch\": 82}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.332492, \"epoch\": 82}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.538841, \"epoch\": 82}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.475447, \"epoch\": 82}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.228825, \"epoch\": 82}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.187657, \"epoch\": 82}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.714771, \"epoch\": 82}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.701507, \"epoch\": 82}\n",
            "Save done!\n",
            "82 -- TRAINING ==============>\n",
            "EPOCH 82 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.513013, \"epoch\": 83}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.543060, \"epoch\": 83}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.814043, \"epoch\": 83}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.853535, \"epoch\": 83}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.442419, \"epoch\": 83}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.333123, \"epoch\": 83}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.542628, \"epoch\": 83}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.474989, \"epoch\": 83}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.235309, \"epoch\": 83}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.184671, \"epoch\": 83}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.713825, \"epoch\": 83}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.702019, \"epoch\": 83}\n",
            "Save done!\n",
            "83 -- TRAINING ==============>\n",
            "EPOCH 83 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.512365, \"epoch\": 84}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.542724, \"epoch\": 84}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806809, \"epoch\": 84}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.853535, \"epoch\": 84}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.439434, \"epoch\": 84}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.340063, \"epoch\": 84}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.538497, \"epoch\": 84}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.480037, \"epoch\": 84}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.225961, \"epoch\": 84}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.190518, \"epoch\": 84}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.715570, \"epoch\": 84}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.702554, \"epoch\": 84}\n",
            "Save done!\n",
            "84 -- TRAINING ==============>\n",
            "EPOCH 84 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.512059, \"epoch\": 85}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.542338, \"epoch\": 85}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806809, \"epoch\": 85}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.853535, \"epoch\": 85}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.445562, \"epoch\": 85}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.337539, \"epoch\": 85}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.542972, \"epoch\": 85}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.478201, \"epoch\": 85}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.231033, \"epoch\": 85}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.188396, \"epoch\": 85}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.716420, \"epoch\": 85}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.703115, \"epoch\": 85}\n",
            "Save done!\n",
            "85 -- TRAINING ==============>\n",
            "EPOCH 85 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.511025, \"epoch\": 86}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.542031, \"epoch\": 86}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.807234, \"epoch\": 86}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.855219, \"epoch\": 86}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.448390, \"epoch\": 86}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.340063, \"epoch\": 86}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.545152, \"epoch\": 86}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.480496, \"epoch\": 86}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.233775, \"epoch\": 86}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.192267, \"epoch\": 86}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.717411, \"epoch\": 86}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.703429, \"epoch\": 86}\n",
            "Save done!\n",
            "86 -- TRAINING ==============>\n",
            "EPOCH 86 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.510905, \"epoch\": 87}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.541633, \"epoch\": 87}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.802553, \"epoch\": 87}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.853535, \"epoch\": 87}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.448390, \"epoch\": 87}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.345110, \"epoch\": 87}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.543890, \"epoch\": 87}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.483708, \"epoch\": 87}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.229347, \"epoch\": 87}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.194750, \"epoch\": 87}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.718379, \"epoch\": 87}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.703941, \"epoch\": 87}\n",
            "Save done!\n",
            "87 -- TRAINING ==============>\n",
            "EPOCH 87 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.509410, \"epoch\": 88}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.541299, \"epoch\": 88}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.812766, \"epoch\": 88}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.851852, \"epoch\": 88}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.446190, \"epoch\": 88}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.351420, \"epoch\": 88}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.545037, \"epoch\": 88}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.487838, \"epoch\": 88}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.237204, \"epoch\": 88}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.198286, \"epoch\": 88}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.720401, \"epoch\": 88}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.704340, \"epoch\": 88}\n",
            "Save done!\n",
            "88 -- TRAINING ==============>\n",
            "EPOCH 88 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.509903, \"epoch\": 89}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.540938, \"epoch\": 89}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808936, \"epoch\": 89}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.850168, \"epoch\": 89}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.454988, \"epoch\": 89}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.350789, \"epoch\": 89}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.550430, \"epoch\": 89}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.486921, \"epoch\": 89}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.240839, \"epoch\": 89}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.196028, \"epoch\": 89}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.720082, \"epoch\": 89}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.704735, \"epoch\": 89}\n",
            "Save done!\n",
            "89 -- TRAINING ==============>\n",
            "EPOCH 89 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.509052, \"epoch\": 90}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.540643, \"epoch\": 90}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.805957, \"epoch\": 90}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.850168, \"epoch\": 90}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.452160, \"epoch\": 90}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.348896, \"epoch\": 90}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.547562, \"epoch\": 90}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.485544, \"epoch\": 90}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.235688, \"epoch\": 90}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.194445, \"epoch\": 90}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.720055, \"epoch\": 90}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.705101, \"epoch\": 90}\n",
            "Save done!\n",
            "90 -- TRAINING ==============>\n",
            "EPOCH 90 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.508169, \"epoch\": 91}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.540217, \"epoch\": 91}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 91}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.845118, \"epoch\": 91}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.457502, \"epoch\": 91}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.353312, \"epoch\": 91}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.552610, \"epoch\": 91}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.487380, \"epoch\": 91}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.244120, \"epoch\": 91}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.192962, \"epoch\": 91}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.722364, \"epoch\": 91}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.705610, \"epoch\": 91}\n",
            "Save done!\n",
            "91 -- TRAINING ==============>\n",
            "EPOCH 91 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.507722, \"epoch\": 92}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.539957, \"epoch\": 92}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 92}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.843434, \"epoch\": 92}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.456559, \"epoch\": 92}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.354574, \"epoch\": 92}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.551922, \"epoch\": 92}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.487838, \"epoch\": 92}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.243342, \"epoch\": 92}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.192300, \"epoch\": 92}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.722486, \"epoch\": 92}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.706158, \"epoch\": 92}\n",
            "Save done!\n",
            "92 -- TRAINING ==============>\n",
            "EPOCH 92 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.507235, \"epoch\": 93}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.539510, \"epoch\": 93}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.811064, \"epoch\": 93}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.845118, \"epoch\": 93}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.452474, \"epoch\": 93}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.357098, \"epoch\": 93}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.549168, \"epoch\": 93}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.490133, \"epoch\": 93}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.240775, \"epoch\": 93}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.196130, \"epoch\": 93}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.722715, \"epoch\": 93}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.706518, \"epoch\": 93}\n",
            "Save done!\n",
            "93 -- TRAINING ==============>\n",
            "EPOCH 93 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.506671, \"epoch\": 94}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.539263, \"epoch\": 94}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 94}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 94}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.460644, \"epoch\": 94}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.360883, \"epoch\": 94}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.554905, \"epoch\": 94}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.491969, \"epoch\": 94}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.246714, \"epoch\": 94}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.195868, \"epoch\": 94}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.723501, \"epoch\": 94}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.706802, \"epoch\": 94}\n",
            "Save done!\n",
            "94 -- TRAINING ==============>\n",
            "EPOCH 94 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.505913, \"epoch\": 95}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.539018, \"epoch\": 95}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809362, \"epoch\": 95}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 95}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.461744, \"epoch\": 95}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.360252, \"epoch\": 95}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.555479, \"epoch\": 95}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.491510, \"epoch\": 95}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.246821, \"epoch\": 95}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.195341, \"epoch\": 95}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.725444, \"epoch\": 95}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.707071, \"epoch\": 95}\n",
            "Save done!\n",
            "95 -- TRAINING ==============>\n",
            "EPOCH 95 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.504938, \"epoch\": 96}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.538746, \"epoch\": 96}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.814043, \"epoch\": 96}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 96}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.468028, \"epoch\": 96}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.362145, \"epoch\": 96}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.561331, \"epoch\": 96}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.492887, \"epoch\": 96}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.256410, \"epoch\": 96}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.196923, \"epoch\": 96}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.726836, \"epoch\": 96}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.707279, \"epoch\": 96}\n",
            "Save done!\n",
            "96 -- TRAINING ==============>\n",
            "EPOCH 96 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.503954, \"epoch\": 97}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.538463, \"epoch\": 97}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.804681, \"epoch\": 97}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 97}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.465515, \"epoch\": 97}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.362776, \"epoch\": 97}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.556971, \"epoch\": 97}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.493346, \"epoch\": 97}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.245539, \"epoch\": 97}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.197450, \"epoch\": 97}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.728124, \"epoch\": 97}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.707788, \"epoch\": 97}\n",
            "Save done!\n",
            "97 -- TRAINING ==============>\n",
            "EPOCH 97 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.503666, \"epoch\": 98}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.538155, \"epoch\": 98}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808936, \"epoch\": 98}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 98}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.465515, \"epoch\": 98}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.368454, \"epoch\": 98}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.558118, \"epoch\": 98}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.497476, \"epoch\": 98}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.249535, \"epoch\": 98}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202184, \"epoch\": 98}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.728959, \"epoch\": 98}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.708090, \"epoch\": 98}\n",
            "Save done!\n",
            "98 -- TRAINING ==============>\n",
            "EPOCH 98 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.503671, \"epoch\": 99}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.537593, \"epoch\": 99}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806809, \"epoch\": 99}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.841751, \"epoch\": 99}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.468657, \"epoch\": 99}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.370978, \"epoch\": 99}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.559839, \"epoch\": 99}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.499312, \"epoch\": 99}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.250136, \"epoch\": 99}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.204282, \"epoch\": 99}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.728475, \"epoch\": 99}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.708426, \"epoch\": 99}\n",
            "Save done!\n",
            "99 -- TRAINING ==============>\n",
            "EPOCH 99 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.502565, \"epoch\": 100}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.537283, \"epoch\": 100}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806383, \"epoch\": 100}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 100}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.468814, \"epoch\": 100}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.370978, \"epoch\": 100}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.559839, \"epoch\": 100}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.498853, \"epoch\": 100}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.249867, \"epoch\": 100}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202585, \"epoch\": 100}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.730638, \"epoch\": 100}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.708787, \"epoch\": 100}\n",
            "Save done!\n",
            "100 -- TRAINING ==============>\n",
            "EPOCH 100 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.502400, \"epoch\": 101}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.537147, \"epoch\": 101}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809787, \"epoch\": 101}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 101}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.476669, \"epoch\": 101}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.370978, \"epoch\": 101}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.566495, \"epoch\": 101}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.498853, \"epoch\": 101}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.259551, \"epoch\": 101}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202585, \"epoch\": 101}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.730724, \"epoch\": 101}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.709115, \"epoch\": 101}\n",
            "Save done!\n",
            "101 -- TRAINING ==============>\n",
            "EPOCH 101 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.501529, \"epoch\": 102}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.536906, \"epoch\": 102}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.812340, \"epoch\": 102}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 102}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.474313, \"epoch\": 102}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.369085, \"epoch\": 102}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.565462, \"epoch\": 102}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.497476, \"epoch\": 102}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.259995, \"epoch\": 102}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.201009, \"epoch\": 102}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.732355, \"epoch\": 102}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.709553, \"epoch\": 102}\n",
            "Save done!\n",
            "102 -- TRAINING ==============>\n",
            "EPOCH 102 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.500907, \"epoch\": 103}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.536614, \"epoch\": 103}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806809, \"epoch\": 103}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 103}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.470542, \"epoch\": 103}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.367192, \"epoch\": 103}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.561216, \"epoch\": 103}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.496099, \"epoch\": 103}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.251695, \"epoch\": 103}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.199431, \"epoch\": 103}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.732584, \"epoch\": 103}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.709875, \"epoch\": 103}\n",
            "Save done!\n",
            "103 -- TRAINING ==============>\n",
            "EPOCH 103 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.500624, \"epoch\": 104}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.536381, \"epoch\": 104}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.803404, \"epoch\": 104}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 104}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.479340, \"epoch\": 104}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.367823, \"epoch\": 104}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.566724, \"epoch\": 104}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.496558, \"epoch\": 104}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.255801, \"epoch\": 104}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.199957, \"epoch\": 104}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.731954, \"epoch\": 104}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.710067, \"epoch\": 104}\n",
            "Save done!\n",
            "104 -- TRAINING ==============>\n",
            "EPOCH 104 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.499434, \"epoch\": 105}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.536274, \"epoch\": 105}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 105}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.840067, \"epoch\": 105}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.482482, \"epoch\": 105}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.374132, \"epoch\": 105}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.570855, \"epoch\": 105}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.501147, \"epoch\": 105}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.264755, \"epoch\": 105}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.205208, \"epoch\": 105}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.734926, \"epoch\": 105}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.710356, \"epoch\": 105}\n",
            "Save done!\n",
            "105 -- TRAINING ==============>\n",
            "EPOCH 105 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.499323, \"epoch\": 106}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.536073, \"epoch\": 106}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808936, \"epoch\": 106}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.838384, \"epoch\": 106}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.479340, \"epoch\": 106}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.379811, \"epoch\": 106}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.568216, \"epoch\": 106}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.504819, \"epoch\": 106}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.260964, \"epoch\": 106}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.208232, \"epoch\": 106}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.735222, \"epoch\": 106}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.710730, \"epoch\": 106}\n",
            "Save done!\n",
            "106 -- TRAINING ==============>\n",
            "EPOCH 106 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.497435, \"epoch\": 107}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.535835, \"epoch\": 107}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.807660, \"epoch\": 107}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.838384, \"epoch\": 107}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.484053, \"epoch\": 107}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.377287, \"epoch\": 107}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.571314, \"epoch\": 107}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.502983, \"epoch\": 107}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.263675, \"epoch\": 107}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.206137, \"epoch\": 107}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.737704, \"epoch\": 107}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.710924, \"epoch\": 107}\n",
            "Save done!\n",
            "107 -- TRAINING ==============>\n",
            "EPOCH 107 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.497077, \"epoch\": 108}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.535648, \"epoch\": 108}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.806383, \"epoch\": 108}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.835017, \"epoch\": 108}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.485467, \"epoch\": 108}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.380442, \"epoch\": 108}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.572002, \"epoch\": 108}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.504360, \"epoch\": 108}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.263657, \"epoch\": 108}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.205388, \"epoch\": 108}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.737351, \"epoch\": 108}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.711122, \"epoch\": 108}\n",
            "Save done!\n",
            "108 -- TRAINING ==============>\n",
            "EPOCH 108 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.497213, \"epoch\": 109}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.535369, \"epoch\": 109}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809362, \"epoch\": 109}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.835017, \"epoch\": 109}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.483896, \"epoch\": 109}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.375394, \"epoch\": 109}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.571658, \"epoch\": 109}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.500688, \"epoch\": 109}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.265131, \"epoch\": 109}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.201187, \"epoch\": 109}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.738345, \"epoch\": 109}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.711326, \"epoch\": 109}\n",
            "Save done!\n",
            "109 -- TRAINING ==============>\n",
            "EPOCH 109 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.496503, \"epoch\": 110}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.535149, \"epoch\": 110}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.810213, \"epoch\": 110}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.835017, \"epoch\": 110}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.488295, \"epoch\": 110}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.376025, \"epoch\": 110}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.575100, \"epoch\": 110}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.501147, \"epoch\": 110}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.269565, \"epoch\": 110}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.201713, \"epoch\": 110}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.738373, \"epoch\": 110}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.711639, \"epoch\": 110}\n",
            "Save done!\n",
            "110 -- TRAINING ==============>\n",
            "EPOCH 110 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.496415, \"epoch\": 111}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.534763, \"epoch\": 111}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.801277, \"epoch\": 111}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.833333, \"epoch\": 111}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.489552, \"epoch\": 111}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.379180, \"epoch\": 111}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.573609, \"epoch\": 111}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.502983, \"epoch\": 111}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.262303, \"epoch\": 111}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202657, \"epoch\": 111}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.738601, \"epoch\": 111}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.711985, \"epoch\": 111}\n",
            "Save done!\n",
            "111 -- TRAINING ==============>\n",
            "EPOCH 111 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.495180, \"epoch\": 112}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.534481, \"epoch\": 112}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808936, \"epoch\": 112}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.831650, \"epoch\": 112}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.485939, \"epoch\": 112}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.380442, \"epoch\": 112}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.573035, \"epoch\": 112}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.503442, \"epoch\": 112}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.266425, \"epoch\": 112}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202027, \"epoch\": 112}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.741258, \"epoch\": 112}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.712115, \"epoch\": 112}\n",
            "Save done!\n",
            "112 -- TRAINING ==============>\n",
            "EPOCH 112 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.493223, \"epoch\": 113}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.534500, \"epoch\": 113}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.802553, \"epoch\": 113}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.829966, \"epoch\": 113}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.489709, \"epoch\": 113}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.383596, \"epoch\": 113}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.574068, \"epoch\": 113}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.505278, \"epoch\": 113}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.263619, \"epoch\": 113}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202979, \"epoch\": 113}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.743656, \"epoch\": 113}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.712332, \"epoch\": 113}\n",
            "113 -- TRAINING ==============>\n",
            "EPOCH 113 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.493951, \"epoch\": 114}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.534223, \"epoch\": 114}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808085, \"epoch\": 114}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.831650, \"epoch\": 114}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.488610, \"epoch\": 114}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.380442, \"epoch\": 114}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.574756, \"epoch\": 114}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.503442, \"epoch\": 114}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.267846, \"epoch\": 114}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202027, \"epoch\": 114}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.743158, \"epoch\": 114}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.712632, \"epoch\": 114}\n",
            "Save done!\n",
            "114 -- TRAINING ==============>\n",
            "EPOCH 114 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.493593, \"epoch\": 115}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.534124, \"epoch\": 115}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.805957, \"epoch\": 115}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.829966, \"epoch\": 115}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.495365, \"epoch\": 115}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.383596, \"epoch\": 115}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.579116, \"epoch\": 115}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.505278, \"epoch\": 115}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.271476, \"epoch\": 115}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.202979, \"epoch\": 115}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.743014, \"epoch\": 115}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.712903, \"epoch\": 115}\n",
            "Save done!\n",
            "115 -- TRAINING ==============>\n",
            "EPOCH 115 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.492134, \"epoch\": 116}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.533876, \"epoch\": 116}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.809787, \"epoch\": 116}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.829966, \"epoch\": 116}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.498036, \"epoch\": 116}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.389274, \"epoch\": 116}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.582100, \"epoch\": 116}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.509408, \"epoch\": 116}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.277243, \"epoch\": 116}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.207703, \"epoch\": 116}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.745055, \"epoch\": 116}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.713080, \"epoch\": 116}\n",
            "Save done!\n",
            "116 -- TRAINING ==============>\n",
            "EPOCH 116 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.492058, \"epoch\": 117}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.533548, \"epoch\": 117}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808085, \"epoch\": 117}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.829966, \"epoch\": 117}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.496779, \"epoch\": 117}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.390536, \"epoch\": 117}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.580723, \"epoch\": 117}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.510326, \"epoch\": 117}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.274622, \"epoch\": 117}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.208751, \"epoch\": 117}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.744906, \"epoch\": 117}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.713370, \"epoch\": 117}\n",
            "Save done!\n",
            "117 -- TRAINING ==============>\n",
            "EPOCH 117 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.491301, \"epoch\": 118}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.533324, \"epoch\": 118}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.808085, \"epoch\": 118}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.829966, \"epoch\": 118}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.494894, \"epoch\": 118}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.394953, \"epoch\": 118}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.579346, \"epoch\": 118}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.513538, \"epoch\": 118}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.273057, \"epoch\": 118}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.212414, \"epoch\": 118}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.746407, \"epoch\": 118}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.713626, \"epoch\": 118}\n",
            "Save done!\n",
            "118 -- TRAINING ==============>\n",
            "EPOCH 118 -- VALIDATION ==============>\n",
            "{\"metric\": \"train_loss\", \"value\": 0.489900, \"epoch\": 119}\n",
            "{\"metric\": \"val_loss\", \"value\": 0.533245, \"epoch\": 119}\n",
            "{\"metric\": \"train_sensitivity\", \"value\": 0.812340, \"epoch\": 119}\n",
            "{\"metric\": \"val_sensitivity\", \"value\": 0.831650, \"epoch\": 119}\n",
            "{\"metric\": \"train_specificity\", \"value\": 0.498036, \"epoch\": 119}\n",
            "{\"metric\": \"val_specificity\", \"value\": 0.391798, \"epoch\": 119}\n",
            "{\"metric\": \"train_accuracy\", \"value\": 0.582788, \"epoch\": 119}\n",
            "{\"metric\": \"val_accuracy\", \"value\": 0.511703, \"epoch\": 119}\n",
            "{\"metric\": \"train_mcc\", \"value\": 0.279610, \"epoch\": 119}\n",
            "{\"metric\": \"val_mcc\", \"value\": 0.211465, \"epoch\": 119}\n",
            "{\"metric\": \"train_auc\", \"value\": 0.748705, \"epoch\": 119}\n",
            "{\"metric\": \"val_auc\", \"value\": 0.714032, \"epoch\": 119}\n",
            "Save done!\n",
            "119 -- TRAINING ==============>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ufh3QpwdoM"
      },
      "source": [
        "#single_run.py\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorboard_logger\n",
        "from torch.utils.data import dataloader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "plt.switch_backend('agg')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#saved models\n",
        "models_path = '/content'\n",
        "\n",
        "def train_validate_united(train_dataset,\n",
        "                          val_dataset,\n",
        "                          train_device,\n",
        "                          val_device,\n",
        "                          use_mat,\n",
        "                          use_mord,\n",
        "                          opt_type,\n",
        "                          n_epoch,\n",
        "                          batch_size,\n",
        "                          metrics,\n",
        "                          hash_code,\n",
        "                          lr):\n",
        "    train_loader = dataloader.DataLoader(dataset=train_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         collate_fn=custom_collate,\n",
        "                                         shuffle=False)\n",
        "\n",
        "    val_loader = dataloader.DataLoader(dataset=val_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       collate_fn=custom_collate,\n",
        "                                       shuffle=False)\n",
        "    \n",
        "    #tensorflow_logger fix\n",
        "    #tensorboard_logger.clean_default_logger()\n",
        "    try:\n",
        "      tensorboard_logger.configure('logs/' + hash_code)\n",
        "    except Exception:\n",
        "      print('tensorboard_logger already configured!')\n",
        "    \n",
        "\n",
        "    sm, mord_ft, non_mord_ft, label = next(iter(train_loader))\n",
        "    smiles_len = int(non_mord_ft.shape[1]/42)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    united_net = UnitedNet(dense_dim=train_dataset.get_dim('mord'), smiles_len=smiles_len,\n",
        "                           use_mat=use_mat, use_mord=use_mord).to(train_device)\n",
        "\n",
        "    if opt_type == 'sgd':\n",
        "        opt = optim.SGD(united_net.parameters(),\n",
        "                        lr=lr,\n",
        "                        momentum=0.99)\n",
        "    elif opt_type == 'adam':\n",
        "        opt = optim.Adam(united_net.parameters(),\n",
        "                         lr=lr)\n",
        "\n",
        "    min_loss = 100  # arbitary large number\n",
        "    early_stop_count = 0\n",
        "    for e in range(n_epoch):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_outputs = []\n",
        "        val_outputs = []\n",
        "        train_labels = []\n",
        "        val_labels = []\n",
        "        print(e, '--', 'TRAINING ==============>')\n",
        "        for i, (mord_ft, non_mord_ft, label) in enumerate(train_loader):\n",
        "            united_net.train()\n",
        "            mord_ft = mord_ft.float().to(train_device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(train_device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(train_device)\n",
        "            # print(label)\n",
        "            label = label.float().to(train_device)\n",
        "\n",
        "            # Forward\n",
        "            opt.zero_grad()\n",
        "            outputs = united_net(non_mord_ft, mord_ft, mat_ft)\n",
        "            \n",
        "            outputs = torch.squeeze(outputs)\n",
        "            \n",
        "            loss = criterion(outputs, label)\n",
        "            train_losses.append(float(loss.item()))\n",
        "            train_outputs.extend(outputs)\n",
        "            train_labels.extend(label)\n",
        "\n",
        "            # Parameters update\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        # Validate after each epoch\n",
        "        print('EPOCH', e, '--', 'VALIDATION ==============>')\n",
        "        for i, (mord_ft, non_mord_ft, label) in enumerate(val_loader):\n",
        "            united_net.eval()\n",
        "            mord_ft = mord_ft.float().to(val_device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(val_device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(train_device)\n",
        "            label = label.float().to(val_device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = united_net(non_mord_ft, mord_ft, mat_ft)\n",
        "                \n",
        "                outputs = torch.squeeze(outputs)\n",
        "                \n",
        "                loss = criterion(outputs, label)\n",
        "                val_losses.append(float(loss.item()))\n",
        "                val_outputs.extend(outputs)\n",
        "                val_labels.extend(label)\n",
        "\n",
        "        train_outputs = torch.stack(train_outputs)\n",
        "        val_outputs = torch.stack(val_outputs)\n",
        "        train_labels = torch.stack(train_labels)\n",
        "        val_labels = torch.stack(val_labels)\n",
        "        tensorboard_logger.log_value('train_loss', sum(train_losses) / len(train_losses), e + 1)\n",
        "        tensorboard_logger.log_value('val_loss', sum(val_losses) / len(val_losses), e + 1)\n",
        "        print('{\"metric\": \"train_loss\", \"value\": %f, \"epoch\": %d}' % (sum(train_losses) / len(train_losses), e + 1))\n",
        "        print('{\"metric\": \"val_loss\", \"value\": %f, \"epoch\": %d}' % (sum(val_losses) / len(val_losses), e + 1))\n",
        "        for key in metrics.keys():\n",
        "            train_metric = metrics[key](train_labels, train_outputs)\n",
        "            val_metric = metrics[key](val_labels, val_outputs)\n",
        "            print('{\"metric\": \"%s\", \"value\": %f, \"epoch\": %d}' % ('train_' + key, train_metric, e + 1))\n",
        "            print('{\"metric\": \"%s\", \"value\": %f, \"epoch\": %d}' % ('val_' + key, val_metric, e + 1))\n",
        "            tensorboard_logger.log_value('train_{}'.format(key),\n",
        "                                         train_metric, e + 1)\n",
        "            tensorboard_logger.log_value('val_{}'.format(key),\n",
        "                                         val_metric, e + 1)\n",
        "        loss_epoch = sum(val_losses) / len(val_losses)\n",
        "        if loss_epoch < min_loss:\n",
        "            early_stop_count = 0\n",
        "            min_loss = loss_epoch\n",
        "            save_model(united_net, models_path, hash_code)\n",
        "        else:\n",
        "            early_stop_count += 1\n",
        "            if early_stop_count > 30:\n",
        "                print('Traning can not improve from epoch {}\\tBest loss: {}'.format(e, min_loss))\n",
        "                break\n",
        "\n",
        "    train_metrics = {}\n",
        "    val_metrics = {}\n",
        "    for key in metrics.keys():\n",
        "        train_metrics[key] = metrics[key](train_labels, train_outputs)\n",
        "        val_metrics[key] = metrics[key](val_labels, val_outputs)\n",
        "\n",
        "    return train_metrics, val_metrics\n",
        "\n",
        "\n",
        "def predict(dataset, model_path, device='cpu'):\n",
        "    loader = dataloader.DataLoader(dataset=dataset,\n",
        "                                   batch_size=128,\n",
        "                                   collate_fn=custom_collate,\n",
        "                                   shuffle=False)\n",
        "    \n",
        "    sm, mord_ft, non_mord_ft, label = next(iter(loader))\n",
        "    smiles_len = int(non_mord_ft.shape[1]/42)\n",
        "\n",
        "    united_net = UnitedNet(dense_dim=dataset.get_dim('mord'), smiles_len=smiles_len, use_mat=True).to(device)\n",
        "    united_net.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    # EVAL_MODE\n",
        "    united_net.eval()\n",
        "    probas = []\n",
        "    for i, (mord_ft, non_mord_ft, label) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "            mord_ft = mord_ft.float().to(device)\n",
        "            non_mord_ft = non_mord_ft.view((-1, int(non_mord_ft.shape[1]/42), 42)).float().to(device)\n",
        "            mat_ft = non_mord_ft.squeeze(1).float().to(device)\n",
        "            # Forward to get smiles and equivalent weights\n",
        "            proba = united_net(non_mord_ft, mord_ft, mat_ft).cpu()\n",
        "            probas.append(proba)\n",
        "    print('Forward done !!!')\n",
        "    probas = np.concatenate(probas)\n",
        "    return probas\n",
        "\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred, hashcode=''):\n",
        "\n",
        "    if not os.path.exists('vis/'):\n",
        "        os.makedirs('vis/')\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
        "    auc_roc = metrics.roc_auc_score(y_true, y_pred)\n",
        "    print('AUC: {:4f}'.format(auc_roc))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.savefig('vis/ROC_{}'.format(hashcode + '.png'))\n",
        "    plt.clf()  # Clear figure\n",
        "\n",
        "\n",
        "def plot_precision_recall(y_true, y_pred, hashcode=''):\n",
        "\n",
        "    if not os.path.exists('vis/'):\n",
        "        os.makedirs('vis/')\n",
        "\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    plt.plot(thresholds, precisions[:-1], label=\"Precision\")\n",
        "    plt.plot(thresholds, recalls[:-1], label=\"Recall\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylim([0, 1])\n",
        "    plt.savefig('vis/PR_{}'.format(hashcode + '.png'))\n",
        "    plt.clf()  # Clear figure\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    train_device = 'cuda'\n",
        "    val_device = 'cuda'\n",
        "else:\n",
        "    train_device = 'cpu'\n",
        "    val_device = 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7noIRvPwqFi"
      },
      "source": [
        "#nets.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "\n",
        "class UnitedNet(nn.Module):\n",
        "    def __init__(self, dense_dim, smiles_len, use_mord=True, use_mat=True, infer=False, dir_path=None, vis_thresh=0.2):\n",
        "        super(UnitedNet, self).__init__()\n",
        "        self.use_mord = use_mord\n",
        "        self.use_mat = use_mat\n",
        "        self.infer = infer\n",
        "        self.vis_thresh = vis_thresh\n",
        "        self.dir_path = dir_path\n",
        "        self.smiles_len = smiles_len\n",
        "        \n",
        "        if self.dir_path:\n",
        "            self.smile_out_f = open(os.path.join(self.dir_path, 'smiles.txt'), 'w')\n",
        "            self.weight_f = open(os.path.join(self.dir_path, 'weight.txt'), 'w')\n",
        "\n",
        "        # PARAMS FOR CNN NET\n",
        "        # Convolutionals\n",
        "        self.conv_conv1 = nn.Conv1d(42, 64, kernel_size=5, padding=2)\n",
        "        self.conv_pool = nn.MaxPool1d(5)\n",
        "        self.conv_conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Fully connected\n",
        "        \n",
        "        self.conv_fc = nn.Linear(128*12, self.smiles_len)#self.smiles_len // 5 // 5 , 120)\n",
        "\n",
        "        # Batch norms\n",
        "        self.conv_batch_norm1 = nn.BatchNorm1d(64)\n",
        "        self.conv_batch_norm2 = nn.BatchNorm1d(128)\n",
        "        # # PARAMS FOR CNN NET\n",
        "        # # Convolutionals\n",
        "        # self.conv_conv1 = nn.Conv2d(1, 6, kernel_size=3) #smiles_len-2\n",
        "        # self.conv_pool = nn.MaxPool2d(2, 2) #smiles_len/2\n",
        "        # self.conv_conv2 = nn.Conv2d(6, 16, kernel_size=3) #smiles_len-2\n",
        "\n",
        "        # # Fully connected\n",
        "        # self.conv_fc = nn.Linear(16 * 9 * int(((self.smiles_len-2)/2 - 2)/2), self.smiles_len)\n",
        "\n",
        "        # # Batch norms\n",
        "        # self.conv_batch_norm1 = nn.BatchNorm2d(6)\n",
        "        # self.conv_batch_norm2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # PARAMS FOR DENSE NET\n",
        "        # Fully connected\n",
        "        if self.use_mord:\n",
        "            self.dense_fc1 = nn.Linear(dense_dim, 512)\n",
        "            self.dense_fc2 = nn.Linear(512, 128)\n",
        "            self.dense_fc3 = nn.Linear(128, 64)\n",
        "\n",
        "            # Batch norms\n",
        "            self.dense_batch_norm1 = nn.BatchNorm1d(512)\n",
        "            self.dense_batch_norm2 = nn.BatchNorm1d(128)\n",
        "            self.dense_batch_norm3 = nn.BatchNorm1d(64)\n",
        "\n",
        "            # Dropouts\n",
        "            self.dense_dropout = nn.Dropout()\n",
        "\n",
        "        # PARAMS FOR ATTENTION NET\n",
        "        if self.use_mat:\n",
        "            #self.att_fc = nn.Linear(256, 1)\n",
        "            self.att_fc = nn.Linear(self.smiles_len+42+64, 1)\n",
        "        else:\n",
        "            self.comb_fc_alt = nn.Linear(128, 1)\n",
        "\n",
        "        # PARAMS FOR COMBINED NET\n",
        "        if self.use_mord:\n",
        "            self.comb_fc = nn.Linear(self.smiles_len+64, 1)\n",
        "        else:\n",
        "            self.comb_fc = nn.Linear(self.smiles_len, 1)\n",
        "\n",
        "    def forward(self, x_non_mord, x_mord, x_mat, smiles=None):\n",
        "        # FORWARD CNN\n",
        "        x_non_mord = torch.transpose(x_non_mord, -1,-2)\n",
        "\n",
        "        x_non_mord = self.conv_conv1(x_non_mord)\n",
        "        x_non_mord = self.conv_batch_norm1(x_non_mord)\n",
        "        x_non_mord = F.relu(x_non_mord)\n",
        "        x_non_mord = self.conv_pool(x_non_mord)\n",
        "\n",
        "        x_non_mord = self.conv_conv2(x_non_mord)\n",
        "        x_non_mord = self.conv_batch_norm2(x_non_mord)\n",
        "        x_non_mord = F.relu(x_non_mord)\n",
        "        x_non_mord = self.conv_pool(x_non_mord)\n",
        "\n",
        "        # print(x_non_mord.shape)\n",
        "        x_non_mord = x_non_mord.view(x_non_mord.size(0), -1)\n",
        "        if self.use_mat:\n",
        "            x_non_mord = F.sigmoid(self.conv_fc(x_non_mord))\n",
        "        else:\n",
        "            x_non_mord = F.relu(self.conv_fc(x_non_mord))\n",
        "\n",
        "        # FORWARD DENSE\n",
        "        if self.use_mord:\n",
        "            x_mord = F.relu(self.dense_fc1(x_mord))\n",
        "            x_mord = self.dense_batch_norm1(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "            x_mord = F.relu(self.dense_fc2(x_mord))\n",
        "            x_mord = self.dense_batch_norm2(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "            x_mord = F.relu(self.dense_fc3(x_mord))\n",
        "            x_mord = self.dense_batch_norm3(x_mord)\n",
        "            x_mord = self.dense_dropout(x_mord)\n",
        "\n",
        "        # FORWARD ATTENTION\n",
        "        if self.use_mat:\n",
        "            x_mat = torch.bmm(x_mat.permute(0, 2, 1), x_non_mord.unsqueeze(-1)).squeeze(-1)\n",
        "            x_mat = torch.cat([x_mat, x_non_mord], dim=1)\n",
        "\n",
        "            if self.use_mord:\n",
        "                x_comb = torch.cat([x_mat, x_mord], dim=1)\n",
        "                probs = torch.sigmoid(self.att_fc(x_comb))\n",
        "                if self.infer:\n",
        "                    if not smiles:\n",
        "                        raise ValueError('Please input smiles')\n",
        "                    alphas = x_comb.cpu().detach().numpy().tolist()\n",
        "                    alphas = [\"\\t\".join([str(round(elem, 4)) for elem in seq]) for seq in alphas]\n",
        "                    prob_list = probs.cpu().detach().numpy().tolist()\n",
        "                    for smile, alpha, prob in zip(smiles, alphas, prob_list):\n",
        "                        if prob[0] > self.vis_thresh:\n",
        "                            self.weight_f.write(alpha + '\\n')\n",
        "                            self.smile_out_f.write(smile + '\\n')\n",
        "                return probs\n",
        "            else:\n",
        "                return torch.sigmoid(self.comb_fc(x_mat))\n",
        "        else:\n",
        "            if self.use_mord:\n",
        "                x_comb = torch.cat([x_non_mord, x_mord], dim=1)\n",
        "            else:\n",
        "                x_comb = x_non_mord\n",
        "            return torch.sigmoid(self.comb_fc(x_comb))\n",
        "\n",
        "    def __del__(self):\n",
        "        print('Closing files ...')\n",
        "        if hasattr(self, 'weight_f'):\n",
        "            self.weight_f.close()\n",
        "        if hasattr(self, 'smile_out_f'):\n",
        "            self.smile_out_f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkL30WafyqzS"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxbQ_DKnyusF"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNefTuiX3oDZ"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNE0GRU5rjue"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxyI_jauSK6"
      },
      "source": [
        "del train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsZFbgqRua7p"
      },
      "source": [
        "del val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgWxyDueptVL"
      },
      "source": [
        "pred_dataset = ANYDataset(path2data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe9ePJhguGeD"
      },
      "source": [
        "trained_model_path = f'/content/model_{hashcode}_BEST'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x5V-S1-rlLW"
      },
      "source": [
        "y_pred = predict(pred_dataset, trained_model_path, train_device)\n",
        "y_true = pred_dataset.label\n",
        "\n",
        "#plots are saved in /content/vis\n",
        "plot_roc_curve(y_true, y_pred, trained_model_path.split('/')[-1])\n",
        "plot_precision_recall(y_true, y_pred, trained_model_path.split('/')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
